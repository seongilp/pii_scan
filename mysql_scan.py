import mysql.connector
import polars as pl
import re
import json
from typing import Dict, List, Tuple, Any, Optional
from datetime import datetime
import warnings
import logging
import concurrent.futures
from functools import partial
from tqdm import tqdm
import matplotlib.pyplot as plt
import seaborn as sns
import os
from dotenv import load_dotenv

warnings.filterwarnings('ignore')


class PrivacyScannerLogger:
    def __init__(self, log_level: str = "INFO"):
        logging.basicConfig(
            level=getattr(logging, log_level),
            format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler('privacy_scanner.log'),
                logging.StreamHandler()
            ]
        )
        self.logger = logging.getLogger(__name__)


class PolarsPrivacyScanner:
    def __init__(self, host: str, user: str, password: str = None, database: str = None, sample_size: int = 100, port: int = 3306):
        """
        Polars ê¸°ë°˜ ê°œì¸ì •ë³´ ìŠ¤ìºë„ˆ

        Args:
            host: MySQL ì„œë²„ í˜¸ìŠ¤íŠ¸
            user: ì‚¬ìš©ìëª…
            password: ë¹„ë°€ë²ˆí˜¸ (ì„ íƒì‚¬í•­ - ë¹„ë°€ë²ˆí˜¸ ì—†ì´ë„ ì ‘ì† ê°€ëŠ¥)
            database: ë°ì´í„°ë² ì´ìŠ¤ëª…
            sample_size: ìƒ˜í”Œë§í•  í–‰ ìˆ˜
            port: MySQL í¬íŠ¸ (ê¸°ë³¸ê°’: 3306)
        """
        self.host = host
        self.user = user
        self.password = password
        self.database = database
        self.port = port
        self.connection = None
        self.sample_size = sample_size

        # ì‹œìŠ¤í…œ ìŠ¤í‚¤ë§ˆ ì œì™¸ ëª©ë¡ (í¬ê´„ì )
        self.system_schemas = {
            # MySQL ê¸°ë³¸ ì‹œìŠ¤í…œ ìŠ¤í‚¤ë§ˆ
            'information_schema',
            'performance_schema', 
            'mysql',
            'sys',
            
            # MySQL 8.0+ ì¶”ê°€ ì‹œìŠ¤í…œ ìŠ¤í‚¤ë§ˆ
            'ndbinfo',
        }

        # ê°œì¸ì •ë³´ íŒ¨í„´ ì •ì˜ - í•œêµ­ í˜•ì‹ìœ¼ë¡œ ì—…ë°ì´íŠ¸
        self.privacy_patterns = {
            'email': r'\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b',
            'phone': r'(\d{2,3}-\d{3,4}-\d{4}|\d{10,11})',
            'ssn': r'\d{6}-[1-4]\d{6}',  # í•œêµ­ ì£¼ë¯¼ë“±ë¡ë²ˆí˜¸ í˜•ì‹
            'card_number': r'5327-\d{4}-\d{4}-\d{4}',  # 5327ë¡œ ì‹œì‘í•˜ëŠ” 16ìë¦¬ ì¹´ë“œë²ˆí˜¸
            'account_number': r'1000-\d{8}',  # 1000ìœ¼ë¡œ ì‹œì‘í•˜ëŠ” 12ìë¦¬ ê³„ì¢Œë²ˆí˜¸
        }

        # ê°œì¸ì •ë³´ ê´€ë ¨ ì»¬ëŸ¼ëª… í‚¤ì›Œë“œ
        self.privacy_keywords = [
            'name', 'email', 'phone', 'mobile', 'tel', 'address', 'addr',
            'ssn', 'social', 'birth', 'birthday', 'card', 'account',
            'user_id', 'customer', 'ê³ ê°', 'personal', 'ê°œì¸'
        ]

        print(f"ğŸš€ Polars ê¸°ë°˜ ê°œì¸ì •ë³´ ìŠ¤ìºë„ˆ ì´ˆê¸°í™” (ìƒ˜í”Œ: {sample_size}ê±´)")

    def validate_config(self) -> bool:
        """ì„¤ì • ìœ íš¨ì„± ê²€ì‚¬"""
        issues = []
        
        if not self.host:
            issues.append("í˜¸ìŠ¤íŠ¸ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
        
        if not self.user:
            issues.append("ì‚¬ìš©ìëª…ì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
        
        # ë¹„ë°€ë²ˆí˜¸ ê²€ì¦ ì œê±° - ë¹„ë°€ë²ˆí˜¸ ì—†ì´ë„ ì ‘ì† ê°€ëŠ¥
        # if not self.password:
        #     issues.append("ë¹„ë°€ë²ˆí˜¸ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
        
        if self.sample_size <= 0:
            issues.append("ìƒ˜í”Œ í¬ê¸°ëŠ” 0ë³´ë‹¤ ì»¤ì•¼ í•©ë‹ˆë‹¤")
        
        if self.port <= 0 or self.port > 65535:
            issues.append("í¬íŠ¸ ë²ˆí˜¸ê°€ ìœ íš¨í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤")
        
        if issues:
            print("âŒ ì„¤ì • ì˜¤ë¥˜:")
            for issue in issues:
                print(f"   â€¢ {issue}")
            return False
        
        return True

    def test_connection(self) -> bool:
        """ì—°ê²° í…ŒìŠ¤íŠ¸"""
        print(f"ğŸ” MySQL ì—°ê²° í…ŒìŠ¤íŠ¸ ì¤‘... ({self.host}:{self.port})")
        
        try:
            # ì—°ê²° íŒŒë¼ë¯¸í„° êµ¬ì„±
            connection_params = {
                'host': self.host,
                'port': self.port,
                'user': self.user,
                'charset': 'utf8mb4',
                'connect_timeout': 10
            }
            
            # ë¹„ë°€ë²ˆí˜¸ê°€ ìˆëŠ” ê²½ìš°ì—ë§Œ ì¶”ê°€
            if self.password:
                connection_params['password'] = self.password
                print(f"   â€¢ ì¸ì¦ ë°©ì‹: ì‚¬ìš©ìëª… + ë¹„ë°€ë²ˆí˜¸")
            else:
                print(f"   â€¢ ì¸ì¦ ë°©ì‹: ì‚¬ìš©ìëª…ë§Œ (ë¹„ë°€ë²ˆí˜¸ ì—†ìŒ)")
            
            # ì—°ê²° í…ŒìŠ¤íŠ¸
            test_connection = mysql.connector.connect(**connection_params)
            
            if test_connection.is_connected():
                cursor = test_connection.cursor()
                cursor.execute("SELECT VERSION()")
                version = cursor.fetchone()[0]
                cursor.close()
                test_connection.close()
                
                print(f"âœ… MySQL ì—°ê²° í…ŒìŠ¤íŠ¸ ì„±ê³µ")
                print(f"   â€¢ ì„œë²„ ë²„ì „: {version}")
                return True
            else:
                print("âŒ MySQL ì—°ê²° í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨")
                return False
                
        except mysql.connector.Error as err:
            error_code = err.errno if hasattr(err, 'errno') else 'Unknown'
            print(f"âŒ MySQL ì—°ê²° í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨ (ì—ëŸ¬ ì½”ë“œ: {error_code})")
            
            if error_code == 2003:
                print("   â€¢ MySQL ì„œë²„ê°€ ì‹¤í–‰ë˜ì§€ ì•Šì•˜ê±°ë‚˜ í˜¸ìŠ¤íŠ¸/í¬íŠ¸ê°€ ì˜ëª»ë˜ì—ˆìŠµë‹ˆë‹¤")
                print("   â€¢ í•´ê²°ë°©ë²•: sudo systemctl start mysql")
            elif error_code == 1045:
                print("   â€¢ ì‚¬ìš©ìëª… ë˜ëŠ” ë¹„ë°€ë²ˆí˜¸ê°€ ì˜ëª»ë˜ì—ˆìŠµë‹ˆë‹¤")
                if not self.password:
                    print("   â€¢ ë¹„ë°€ë²ˆí˜¸ ì—†ì´ ì ‘ì†ì„ ì‹œë„í–ˆì§€ë§Œ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤")
                    print("   â€¢ í•´ê²°ë°©ë²•: ì˜¬ë°”ë¥¸ ë¹„ë°€ë²ˆí˜¸ë¥¼ ì„¤ì •í•˜ê±°ë‚˜ MySQL ì‚¬ìš©ì ê¶Œí•œì„ í™•ì¸í•˜ì„¸ìš”")
                else:
                    print("   â€¢ í•´ê²°ë°©ë²•: MySQL ì‚¬ìš©ì ê³„ì •ì„ í™•ì¸í•˜ì„¸ìš”")
            elif error_code == 1049:
                print("   â€¢ ì§€ì •ëœ ë°ì´í„°ë² ì´ìŠ¤ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤")
            elif error_code == 2013:
                print("   â€¢ ì—°ê²° ì‹œê°„ ì´ˆê³¼ - ë„¤íŠ¸ì›Œí¬ ë¬¸ì œì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤")
            else:
                print(f"   â€¢ ì˜¤ë¥˜ ë©”ì‹œì§€: {err}")
            
            return False

    def connect(self):
        """MySQL ì—°ê²°"""
        # ì„¤ì • ê²€ì¦
        if not self.validate_config():
            return False
        
        # ì—°ê²° í…ŒìŠ¤íŠ¸
        if not self.test_connection():
            return False
        
        try:
            print(f"ğŸ”— MySQLì— ì—°ê²° ì¤‘... ({self.host}:{self.port})")
            
            # ì—°ê²° íŒŒë¼ë¯¸í„° êµ¬ì„±
            connection_params = {
                'host': self.host,
                'port': self.port,
                'user': self.user,
                'charset': 'utf8mb4',
                'autocommit': True,
                'connect_timeout': 30,
                'read_timeout': 60,
                'write_timeout': 60
            }
            
            # ë¹„ë°€ë²ˆí˜¸ê°€ ìˆëŠ” ê²½ìš°ì—ë§Œ ì¶”ê°€
            if self.password:
                connection_params['password'] = self.password
            
            # ë°ì´í„°ë² ì´ìŠ¤ê°€ ì§€ì •ëœ ê²½ìš° ì¶”ê°€
            if self.database:
                connection_params['database'] = self.database
            
            self.connection = mysql.connector.connect(**connection_params)
            
            if self.connection.is_connected():
                print(f"âœ… MySQL ì—°ê²° ì„±ê³µ: {self.host}:{self.port}")
                
                # ì—°ê²° ì •ë³´ ì¶œë ¥
                cursor = self.connection.cursor()
                cursor.execute("SELECT DATABASE()")
                current_db = cursor.fetchone()[0]
                cursor.close()
                
                if current_db:
                    print(f"   â€¢ í˜„ì¬ ë°ì´í„°ë² ì´ìŠ¤: {current_db}")
                else:
                    print(f"   â€¢ ë°ì´í„°ë² ì´ìŠ¤ ë¯¸ì„ íƒ (ì „ì²´ ìŠ¤ìº” ëª¨ë“œ)")
                
                return True
            else:
                print("âŒ MySQL ì—°ê²° ì‹¤íŒ¨")
                return False
                
        except mysql.connector.Error as err:
            print(f"âŒ MySQL ì—°ê²° ì‹¤íŒ¨: {err}")
            return False
        except Exception as e:
            print(f"âŒ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {e}")
            return False

    def disconnect(self):
        """MySQL ì—°ê²° í•´ì œ"""
        if self.connection and self.connection.is_connected():
            self.connection.close()
            print("ğŸ” MySQL ì—°ê²° í•´ì œ")
        else:
            print("â„¹ï¸  ì´ë¯¸ ì—°ê²°ì´ í•´ì œë˜ì—ˆìŠµë‹ˆë‹¤")

    def get_databases(self) -> List[str]:
        """ëª¨ë“  ë°ì´í„°ë² ì´ìŠ¤ ëª©ë¡ ì¡°íšŒ"""
        if not self.connection or not self.connection.is_connected():
            print("âŒ MySQL ì—°ê²°ì´ ì—†ìŠµë‹ˆë‹¤")
            return []
        
        try:
            cursor = self.connection.cursor()
            cursor.execute("SHOW DATABASES")
            databases = [db[0] for db in cursor.fetchall()]
            cursor.close()
            return databases
        except mysql.connector.Error as err:
            print(f"âŒ ë°ì´í„°ë² ì´ìŠ¤ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {err}")
            return []

    def get_tables(self, database: str) -> List[str]:
        """íŠ¹ì • ë°ì´í„°ë² ì´ìŠ¤ì˜ í…Œì´ë¸” ëª©ë¡ ì¡°íšŒ"""
        cursor = self.connection.cursor()
        cursor.execute(f"USE {database}")
        cursor.execute("SHOW TABLES")
        tables = [table[0] for table in cursor.fetchall()]
        cursor.close()
        return tables

    def get_table_info(self, database: str, table: str) -> Dict:
        """í…Œì´ë¸” ì •ë³´ ì¡°íšŒ (í–‰ ìˆ˜, ì»¬ëŸ¼ ì •ë³´)"""
        cursor = self.connection.cursor()
        cursor.execute(f"USE {database}")

        # í–‰ ìˆ˜ ì¡°íšŒ
        cursor.execute(f"SELECT COUNT(*) FROM {table}")
        total_rows = cursor.fetchone()[0]

        # ì»¬ëŸ¼ ì •ë³´ ì¡°íšŒ
        cursor.execute(f"DESCRIBE {table}")
        columns = []
        for row in cursor.fetchall():
            columns.append({
                'name': row[0],
                'type': row[1],
                'null': row[2],
                'key': row[3],
                'default': row[4],
                'extra': row[5]
            })

        cursor.close()
        return {
            'total_rows': total_rows,
            'columns': columns
        }

    def estimate_dataframe_size(self, columns: List[Dict], sample_rows: int) -> Dict:
        """DataFrame ì˜ˆìƒ í¬ê¸° ê³„ì‚°"""
        size_estimates = {
            'int': 8, 'bigint': 8, 'smallint': 4, 'tinyint': 1,
            'float': 8, 'double': 8, 'decimal': 16,
            'varchar': 50, 'text': 200, 'longtext': 1000,
            'char': 20, 'date': 8, 'datetime': 8, 'timestamp': 8,
            'json': 100, 'blob': 500, 'binary': 50
        }

        total_bytes_per_row = 0
        text_columns = 0
        numeric_columns = 0
        date_columns = 0

        for col in columns:
            col_type = col['type'].lower()
            col_size = 8

            for type_key, size in size_estimates.items():
                if type_key in col_type:
                    col_size = size
                    break

            if 'varchar' in col_type or 'char' in col_type:
                import re
                match = re.search(r'\((\d+)\)', col_type)
                if match:
                    declared_length = int(match.group(1))
                    col_size = min(declared_length, 255)
                text_columns += 1
            elif any(t in col_type for t in ['text', 'blob', 'json']):
                text_columns += 1
            elif any(t in col_type for t in ['int', 'float', 'double', 'decimal']):
                numeric_columns += 1
            elif any(t in col_type for t in ['date', 'time', 'timestamp']):
                date_columns += 1

            total_bytes_per_row += col_size

        overhead_factor = 1.3
        estimated_size_bytes = total_bytes_per_row * sample_rows * overhead_factor

        return {
            'total_columns': len(columns),
            'text_columns': text_columns,
            'numeric_columns': numeric_columns,
            'date_columns': date_columns,
            'estimated_bytes_per_row': int(total_bytes_per_row),
            'estimated_total_bytes': int(estimated_size_bytes),
            'estimated_mb': round(estimated_size_bytes / (1024 * 1024), 2),
            'sample_rows': sample_rows
        }

    def estimate_scan_time(self, total_rows: int, columns: int, text_columns: int,
                           estimated_mb: float, sample_rows: int) -> Dict:
        """ìŠ¤ìº” ì‹œê°„ ì˜ˆì¸¡ (Polars ê¸°ì¤€)"""
        base_speed_rows_per_sec = 50000
        regex_speed_factor = 0.3
        text_factor = 1 + (text_columns * 0.1)

        effective_speed = base_speed_rows_per_sec * regex_speed_factor / text_factor

        db_query_time = max(0.1, total_rows / 1000000)
        dataframe_creation_time = max(0.05, estimated_mb / 100)
        pattern_scan_time = sample_rows / effective_speed

        total_estimated_seconds = db_query_time + dataframe_creation_time + pattern_scan_time

        return {
            'engine': 'Polars',
            'db_query_time_sec': round(db_query_time, 2),
            'dataframe_creation_time_sec': round(dataframe_creation_time, 2),
            'pattern_scan_time_sec': round(pattern_scan_time, 2),
            'total_estimated_sec': round(total_estimated_seconds, 2),
            'estimated_rows_per_sec': int(effective_speed),
            'text_columns_factor': round(text_factor, 2)
        }

    def load_table_sample(self, database: str, table: str) -> Tuple[Optional[pl.DataFrame], Dict]:
        """í…Œì´ë¸”ì—ì„œ ìƒ˜í”Œ ë°ì´í„°ë¥¼ Polars DataFrameìœ¼ë¡œ ë¡œë“œ"""
        cursor = self.connection.cursor()
        cursor.execute(f"USE {database}")

        table_info = self.get_table_info(database, table)
        total_rows = table_info['total_rows']

        if total_rows == 0:
            print(f"    âš ï¸  ë¹ˆ í…Œì´ë¸”")
            return None, {'method': 'empty', 'total_rows': 0, 'sampled_rows': 0}

        if total_rows <= self.sample_size:
            query = f"SELECT * FROM {table}"
            sample_method = "ì „ì²´ ë°ì´í„°"
        else:
            query = f"SELECT * FROM {table} ORDER BY RAND() LIMIT {self.sample_size}"
            sample_method = f"ëœë¤ ìƒ˜í”Œë§"

        try:
            cursor.execute(query)
            rows = cursor.fetchall()
            columns = [desc[0] for desc in cursor.description]

            if not rows:
                return None, {'method': 'no_data', 'total_rows': total_rows, 'sampled_rows': 0}

            df = pl.DataFrame(rows, schema=columns)

            sampling_info = {
                'method': sample_method,
                'total_rows': total_rows,
                'sampled_rows': len(rows),
                'sampling_ratio': len(rows) / total_rows if total_rows > 0 else 0
            }

            print(f"    ğŸ“Š {total_rows:,}í–‰ â†’ {len(rows)}í–‰ ìƒ˜í”Œë§ ({sample_method})")

            return df, sampling_info

        except Exception as e:
            print(f"    âŒ ë°ì´í„° ë¡œë“œ ì˜¤ë¥˜: {str(e)}")
            return None, {'method': 'error', 'error': str(e)}
        finally:
            cursor.close()

    def is_privacy_column(self, column_name: str) -> bool:
        """ì»¬ëŸ¼ëª…ì´ ê°œì¸ì •ë³´ ê´€ë ¨ ì»¬ëŸ¼ì¸ì§€ í™•ì¸"""
        column_lower = column_name.lower()
        return any(keyword in column_lower for keyword in self.privacy_keywords)

    def scan_column_patterns(self, df: pl.DataFrame, column: str) -> Dict:
        """Polars DataFrame ì»¬ëŸ¼ì—ì„œ ê°œì¸ì •ë³´ íŒ¨í„´ ìŠ¤ìº”"""
        if df is None:
            return {'error': 'DataFrame is None'}

        try:
            if column not in df.columns:
                return {'error': f'Column {column} not found'}

            col_data = df.select(pl.col(column).filter(pl.col(column).is_not_null())).to_series()
            values = [str(val) for val in col_data.to_list()]

            if not values:
                return {'privacy_matches': {}, 'total_values': 0, 'privacy_count': 0, 'privacy_ratio': 0}

            privacy_matches = {}
            privacy_rows = set()

            for idx, value in enumerate(values):
                for pattern_name, pattern in self.privacy_patterns.items():
                    matches = re.findall(pattern, value)
                    if matches:
                        if pattern_name not in privacy_matches:
                            privacy_matches[pattern_name] = 0
                        privacy_matches[pattern_name] += len(matches)
                        privacy_rows.add(idx)

            total_values = len(values)
            privacy_count = len(privacy_rows)
            privacy_ratio = privacy_count / total_values if total_values > 0 else 0

            return {
                'privacy_matches': privacy_matches,
                'total_values': total_values,
                'privacy_count': privacy_count,
                'privacy_ratio': privacy_ratio,
                'sample_values': self.mask_sample_data(values[:5])
            }

        except Exception as e:
            return {'error': str(e)}

    def mask_sample_data(self, values: List[str]) -> List[str]:
        """ìƒ˜í”Œ ë°ì´í„° ë§ˆìŠ¤í‚¹"""
        masked = []
        for value in values:
            value = re.sub(r'([a-zA-Z0-9._%+-]+)@([a-zA-Z0-9.-]+\.[a-zA-Z]{2,})',
                           lambda m: f"{m.group(1)[:2]}***@{m.group(2)}", value)
            value = re.sub(r'(\d{2,3})-(\d{3,4})-(\d{4})', r'\1-***-\3', value)
            value = re.sub(r'(\d{6})-([1-4])(\d{6})', r'\1-\2******', value)
            value = re.sub(r'(\d{4})-(\d{4})-(\d{4})-(\d{4})', r'\1-****-****-\4', value)

            masked.append(value[:50] + "..." if len(value) > 50 else value)

        return masked

    def analyze_dataframe(self, df: pl.DataFrame, table_name: str, sampling_info: Dict) -> Dict:
        """Polars DataFrame ì „ì²´ ë¶„ì„"""
        if df is None:
            return {
                'table': table_name,
                'sampling_info': sampling_info,
                'columns': {},
                'privacy_score': 0,
                'risk_level': 'EMPTY' if sampling_info.get('total_rows', 0) == 0 else 'ERROR'
            }

        print(f"    ğŸ” DataFrame ë¶„ì„ ì¤‘... (Polars)")

        result = {
            'table': table_name,
            'sampling_info': sampling_info,
            'columns': {},
            'privacy_score': 0,
            'risk_level': 'LOW'
        }

        for column in df.columns:
            column_name = str(column)
            col_type = str(df[column].dtype)
            is_suspicious = self.is_privacy_column(column_name)

            column_result = {
                'type': col_type,
                'suspicious_name': is_suspicious,
                'pattern_scan': None
            }

            if any(t in col_type.lower() for t in ['string', 'utf8', 'str']):
                pattern_result = self.scan_column_patterns(df, column_name)
                column_result['pattern_scan'] = pattern_result

                if 'privacy_matches' in pattern_result and pattern_result['privacy_matches']:
                    pattern_score = len(pattern_result['privacy_matches']) * 3
                    ratio_score = int(pattern_result.get('privacy_ratio', 0) * 10)
                    column_score = pattern_score + ratio_score
                    result['privacy_score'] += column_score

                    print(f"      ğŸš¨ {column_name}: {list(pattern_result['privacy_matches'].keys())} "
                          f"(ë¹„ìœ¨: {pattern_result.get('privacy_ratio', 0):.1%})")

                elif is_suspicious:
                    result['privacy_score'] += 1
                    print(f"      âš ï¸  {column_name}: ì˜ì‹¬ìŠ¤ëŸ¬ìš´ ì»¬ëŸ¼ëª…")

            result['columns'][column_name] = column_result

        if result['privacy_score'] >= 15:
            result['risk_level'] = 'HIGH'
        elif result['privacy_score'] >= 5:
            result['risk_level'] = 'MEDIUM'

        return result

    def scan_table(self, database: str, table: str) -> Dict:
        """í…Œì´ë¸” ìŠ¤ìº” (Polars ê¸°ë°˜)"""
        print(f"  ğŸ“‹ í…Œì´ë¸” ìŠ¤ìº”: {table}")

        df, sampling_info = self.load_table_sample(database, table)
        result = self.analyze_dataframe(df, table, sampling_info)

        print(f"    âœ… ì™„ë£Œ (ìœ„í—˜ë„: {result['risk_level']}, ì ìˆ˜: {result['privacy_score']})")

        return result

    def analyze_database_structure(self, database: str) -> Dict:
        """ë°ì´í„°ë² ì´ìŠ¤ êµ¬ì¡° ë¶„ì„ ë° ì²˜ë¦¬ ë¹„ìš© ì˜ˆì¸¡"""
        print(f"ğŸ” ë°ì´í„°ë² ì´ìŠ¤ êµ¬ì¡° ë¶„ì„ ì¤‘: {database}")

        analysis = {
            'database': database,
            'analysis_time': datetime.now().isoformat(),
            'engine': 'Polars',
            'sample_size': self.sample_size,
            'tables': {},
            'summary': {
                'total_tables': 0,
                'total_rows': 0,
                'total_columns': 0,
                'total_text_columns': 0,
                'estimated_total_mb': 0,
                'estimated_total_scan_time_sec': 0,
                'scannable_tables': 0,
                'empty_tables': 0,
                'large_tables': 0
            }
        }

        try:
            tables = self.get_tables(database)
            analysis['summary']['total_tables'] = len(tables)

            print(f"  ğŸ“Š ë°œê²¬ëœ í…Œì´ë¸”: {len(tables)}ê°œ")

            for table in tables:
                print(f"    ğŸ“‹ ë¶„ì„ ì¤‘: {table}")

                try:
                    table_info = self.get_table_info(database, table)
                    total_rows = table_info['total_rows']
                    columns = table_info['columns']

                    sample_rows = min(total_rows, self.sample_size) if total_rows > 0 else 0
                    size_estimate = self.estimate_dataframe_size(columns, sample_rows)
                    time_estimate = self.estimate_scan_time(
                        total_rows,
                        len(columns),
                        size_estimate['text_columns'],
                        size_estimate['estimated_mb'],
                        sample_rows
                    )

                    table_analysis = {
                        'total_rows': total_rows,
                        'total_columns': len(columns),
                        'columns': columns,
                        'size_estimate': size_estimate,
                        'time_estimate': time_estimate,
                        'status': 'scannable' if total_rows > 0 else 'empty'
                    }

                    analysis['tables'][table] = table_analysis

                    analysis['summary']['total_rows'] += total_rows
                    analysis['summary']['total_columns'] += len(columns)
                    analysis['summary']['total_text_columns'] += size_estimate['text_columns']
                    analysis['summary']['estimated_total_mb'] += size_estimate['estimated_mb']
                    analysis['summary']['estimated_total_scan_time_sec'] += time_estimate['total_estimated_sec']

                    if total_rows == 0:
                        analysis['summary']['empty_tables'] += 1
                    else:
                        analysis['summary']['scannable_tables'] += 1

                    if total_rows >= 1000000:
                        analysis['summary']['large_tables'] += 1

                    print(f"      âœ… {total_rows:,}í–‰, {len(columns)}ì»¬ëŸ¼, "
                          f"~{size_estimate['estimated_mb']}MB, "
                          f"~{time_estimate['total_estimated_sec']}ì´ˆ")

                except Exception as e:
                    analysis['tables'][table] = {
                        'error': str(e),
                        'status': 'error'
                    }
                    print(f"      âŒ ë¶„ì„ ì˜¤ë¥˜: {str(e)}")

        except Exception as e:
            analysis['error'] = str(e)
            print(f"âŒ ë°ì´í„°ë² ì´ìŠ¤ ë¶„ì„ ì˜¤ë¥˜: {str(e)}")

        return analysis

    def scan_database(self, database: str) -> Dict:
        """ë°ì´í„°ë² ì´ìŠ¤ ì „ì²´ ìŠ¤ìº”"""
        print(f"ğŸ” ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤ìº” ì‹œì‘: {database} (Polars ì—”ì§„)")

        scan_results = {
            'database': database,
            'scan_time': datetime.now().isoformat(),
            'engine': 'Polars',
            'sample_size': self.sample_size,
            'tables': {},
            'summary': {
                'total_tables': 0,
                'scanned_tables': 0,
                'high_risk_tables': 0,
                'medium_risk_tables': 0,
                'low_risk_tables': 0,
                'total_privacy_score': 0,
                'total_data_rows': 0,
                'total_sampled_rows': 0
            }
        }

        try:
            tables = self.get_tables(database)
            scan_results['summary']['total_tables'] = len(tables)

            for table in tables:
                table_result = self.scan_table(database, table)
                scan_results['tables'][table] = table_result

                risk_level = table_result.get('risk_level', 'LOW')
                privacy_score = table_result.get('privacy_score', 0)
                sampling_info = table_result.get('sampling_info', {})

                if risk_level == 'HIGH':
                    scan_results['summary']['high_risk_tables'] += 1
                elif risk_level == 'MEDIUM':
                    scan_results['summary']['medium_risk_tables'] += 1
                elif risk_level == 'LOW':
                    scan_results['summary']['low_risk_tables'] += 1

                scan_results['summary']['scanned_tables'] += 1
                scan_results['summary']['total_privacy_score'] += privacy_score
                scan_results['summary']['total_data_rows'] += sampling_info.get('total_rows', 0)
                scan_results['summary']['total_sampled_rows'] += sampling_info.get('sampled_rows', 0)

        except Exception as e:
            scan_results['error'] = str(e)
            print(f"âŒ ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤ìº” ì˜¤ë¥˜: {str(e)}")

        return scan_results

    def generate_structure_report(self, analysis: Dict) -> str:
        """ë°ì´í„°ë² ì´ìŠ¤ êµ¬ì¡° ë¶„ì„ ë¦¬í¬íŠ¸ ìƒì„±"""
        report = []
        report.append("=" * 80)
        report.append("ğŸ—ï¸  ë°ì´í„°ë² ì´ìŠ¤ êµ¬ì¡° ë¶„ì„ ë° ì²˜ë¦¬ ë¹„ìš© ì˜ˆì¸¡ (Polars)")
        report.append("=" * 80)
        report.append(f"ë°ì´í„°ë² ì´ìŠ¤: {analysis['database']}")
        report.append(f"ë¶„ì„ ì‹œê°„: {analysis['analysis_time']}")
        report.append(f"ì²˜ë¦¬ ì—”ì§„: Polars")
        report.append(f"ìƒ˜í”Œ í¬ê¸°: {analysis.get('sample_size', 'Unknown')}ê±´")
        report.append("")

        summary = analysis.get('summary', {})

        report.append("ğŸ“Š ì „ì²´ ìš”ì•½:")
        report.append(f"  â€¢ ì´ í…Œì´ë¸” ìˆ˜: {summary.get('total_tables', 0):,}ê°œ")
        report.append(f"  â€¢ ìŠ¤ìº” ê°€ëŠ¥í•œ í…Œì´ë¸”: {summary.get('scannable_tables', 0):,}ê°œ")
        report.append(f"  â€¢ ë¹ˆ í…Œì´ë¸”: {summary.get('empty_tables', 0):,}ê°œ")
        report.append(f"  â€¢ ëŒ€ìš©ëŸ‰ í…Œì´ë¸” (100ë§Œí–‰+): {summary.get('large_tables', 0):,}ê°œ")
        report.append(f"  â€¢ ì´ ë°ì´í„° í–‰ ìˆ˜: {summary.get('total_rows', 0):,}í–‰")
        report.append(f"  â€¢ ì´ ì»¬ëŸ¼ ìˆ˜: {summary.get('total_columns', 0):,}ê°œ")
        report.append(f"  â€¢ í…ìŠ¤íŠ¸ ì»¬ëŸ¼ ìˆ˜: {summary.get('total_text_columns', 0):,}ê°œ")
        report.append("")

        estimated_mb = summary.get('estimated_total_mb', 0)
        estimated_time = summary.get('estimated_total_scan_time_sec', 0)

        report.append("ğŸ’¾ ì˜ˆìƒ ì²˜ë¦¬ ë¹„ìš© (Polars ì—”ì§„):")
        report.append(f"  â€¢ ì˜ˆìƒ DataFrame í¬ê¸°: {estimated_mb:.1f} MB")
        if estimated_mb < 10:
            report.append(f"    â†’ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: ğŸŸ¢ ë‚®ìŒ")
        elif estimated_mb < 100:
            report.append(f"    â†’ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: ğŸŸ¡ ë³´í†µ")
        else:
            report.append(f"    â†’ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: ğŸ”´ ë†’ìŒ")

        report.append(f"  â€¢ ì˜ˆìƒ ìŠ¤ìº” ì‹œê°„: {estimated_time:.1f}ì´ˆ")
        if estimated_time < 30:
            report.append(f"    â†’ ì²˜ë¦¬ ì‹œê°„: ğŸŸ¢ ë¹ ë¦„")
        elif estimated_time < 300:
            report.append(f"    â†’ ì²˜ë¦¬ ì‹œê°„: ğŸŸ¡ ë³´í†µ")
        else:
            report.append(f"    â†’ ì²˜ë¦¬ ì‹œê°„: ğŸ”´ ì˜¤ë˜ ê±¸ë¦¼")

        if estimated_time > 60:
            minutes = int(estimated_time // 60)
            seconds = int(estimated_time % 60)
            report.append(f"    â†’ ì˜ˆìƒ ì‹œê°„: {minutes}ë¶„ {seconds}ì´ˆ")

        report.append("")

        large_tables = []
        for table_name, table_data in analysis.get('tables', {}).items():
            if table_data.get('total_rows', 0) >= 100000:
                large_tables.append({
                    'name': table_name,
                    'rows': table_data.get('total_rows', 0),
                    'columns': table_data.get('total_columns', 0),
                    'mb': table_data.get('size_estimate', {}).get('estimated_mb', 0),
                    'time': table_data.get('time_estimate', {}).get('total_estimated_sec', 0)
                })

        large_tables.sort(key=lambda x: x['rows'], reverse=True)

        if large_tables:
            report.append("ğŸ“ˆ ëŒ€ìš©ëŸ‰ í…Œì´ë¸” ìƒìœ„ 10ê°œ:")
            for i, table in enumerate(large_tables[:10], 1):
                report.append(f"  {i:2d}. {table['name']}")
                report.append(f"      â€¢ í–‰ ìˆ˜: {table['rows']:,}")
                report.append(f"      â€¢ ì»¬ëŸ¼ ìˆ˜: {table['columns']}")
                report.append(f"      â€¢ ì˜ˆìƒ í¬ê¸°: {table['mb']:.1f} MB")
                report.append(f"      â€¢ ì˜ˆìƒ ì‹œê°„: {table['time']:.1f}ì´ˆ")

            if len(large_tables) > 10:
                report.append(f"  ... ì™¸ {len(large_tables) - 10}ê°œ")
            report.append("")

        report.append("ğŸ’¡ ê¶Œì¥ì‚¬í•­:")

        if estimated_mb > 500:
            report.append("  â€¢ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì´ ë†’ìŠµë‹ˆë‹¤. ìƒ˜í”Œ í¬ê¸°ë¥¼ ì¤„ì´ëŠ” ê²ƒì„ ê³ ë ¤í•˜ì„¸ìš”.")

        if estimated_time > 600:
            report.append("  â€¢ ì²˜ë¦¬ ì‹œê°„ì´ ê¹ë‹ˆë‹¤. íŠ¹ì • í…Œì´ë¸”ë§Œ ì„ íƒì ìœ¼ë¡œ ìŠ¤ìº”í•˜ëŠ” ê²ƒì„ ê³ ë ¤í•˜ì„¸ìš”.")

        if summary.get('large_tables', 0) > 10:
            report.append("  â€¢ ëŒ€ìš©ëŸ‰ í…Œì´ë¸”ì´ ë§ìŠµë‹ˆë‹¤. ë°°ì¹˜ ì²˜ë¦¬ë¥¼ ê³ ë ¤í•˜ì„¸ìš”.")

        if summary.get('total_text_columns', 0) > summary.get('total_columns', 1) * 0.7:
            report.append("  â€¢ í…ìŠ¤íŠ¸ ì»¬ëŸ¼ ë¹„ìœ¨ì´ ë†’ìŠµë‹ˆë‹¤. ì •ê·œì‹ ì²˜ë¦¬ë¡œ ì¸í•´ ì‹œê°„ì´ ë” ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

        report.append("  â€¢ Polars ì—”ì§„ìœ¼ë¡œ ìµœì í™”ëœ ê³ ì„±ëŠ¥ ì²˜ë¦¬ê°€ ì§„í–‰ë©ë‹ˆë‹¤.")

        return "\n".join(report)

    def generate_scan_report(self, scan_results: Dict) -> str:
        """ìŠ¤ìº” ê²°ê³¼ ë¦¬í¬íŠ¸ ìƒì„±"""
        report = []
        report.append("=" * 80)
        report.append("ğŸ“Š MySQL ê°œì¸ì •ë³´ ìŠ¤ìº” ë¦¬í¬íŠ¸ (Polars ì—”ì§„)")
        report.append("=" * 80)
        report.append(f"ë°ì´í„°ë² ì´ìŠ¤: {scan_results['database']}")
        report.append(f"ìŠ¤ìº” ì‹œê°„: {scan_results['scan_time']}")
        report.append(f"ì²˜ë¦¬ ì—”ì§„: Polars")

    def generate_privacy_summary_report(self, scan_results: List[Dict]) -> str:
        """ê°œì¸ì •ë³´ ìŠ¤ìº” ê²°ê³¼ ìš”ì•½ ë¦¬í¬íŠ¸ ìƒì„±"""
        report = []
        report.append("=" * 80)
        report.append("ğŸ” ê°œì¸ì •ë³´ ìŠ¤ìº” ê²°ê³¼ ìš”ì•½ ë¦¬í¬íŠ¸")
        report.append("=" * 80)
        
        # ì „ì²´ í†µê³„
        total_databases = len(scan_results)
        total_tables = sum(r.get('summary', {}).get('total_tables', 0) for r in scan_results)
        total_high_risk = sum(r.get('summary', {}).get('high_risk_tables', 0) for r in scan_results)
        total_medium_risk = sum(r.get('summary', {}).get('medium_risk_tables', 0) for r in scan_results)
        total_score = sum(r.get('summary', {}).get('total_privacy_score', 0) for r in scan_results)
        
        report.append(f"ğŸ“Š ì „ì²´ ìŠ¤ìº” í†µê³„:")
        report.append(f"  â€¢ ìŠ¤ìº”ëœ ë°ì´í„°ë² ì´ìŠ¤: {total_databases}ê°œ")
        report.append(f"  â€¢ ì´ í…Œì´ë¸” ìˆ˜: {total_tables}ê°œ")
        report.append(f"  â€¢ ê³ ìœ„í—˜ í…Œì´ë¸”: {total_high_risk}ê°œ")
        report.append(f"  â€¢ ì¤‘ê°„ìœ„í—˜ í…Œì´ë¸”: {total_medium_risk}ê°œ")
        report.append(f"  â€¢ ì „ì²´ ìœ„í—˜ë„ ì ìˆ˜: {total_score}")
        report.append("")
        
        # ê°œì¸ì •ë³´ ì˜ì‹¬ ì»¬ëŸ¼ ìƒì„¸ ë¶„ì„
        privacy_columns_summary = {}
        suspicious_columns_summary = {}
        
        for db_result in scan_results:
            db_name = db_result.get('database', 'Unknown')
            
            for table_name, table_data in db_result.get('tables', {}).items():
                full_table_name = f"{db_name}.{table_name}"
                
                for col_name, col_data in table_data.get('columns', {}).items():
                    pattern_scan = col_data.get('pattern_scan', {})
                    
                    # íŒ¨í„´ ë§¤ì¹­ëœ ê°œì¸ì •ë³´ ì»¬ëŸ¼
                    if pattern_scan and 'privacy_matches' in pattern_scan and pattern_scan['privacy_matches']:
                        matches = pattern_scan['privacy_matches']
                        total_values = pattern_scan.get('total_values', 0)
                        privacy_count = pattern_scan.get('privacy_count', 0)
                        privacy_ratio = pattern_scan.get('privacy_ratio', 0)
                        sample_values = pattern_scan.get('sample_values', [])
                        
                        key = f"{full_table_name}.{col_name}"
                        if key not in privacy_columns_summary:
                            privacy_columns_summary[key] = {
                                'database': db_name,
                                'table': table_name,
                                'column': col_name,
                                'column_type': col_data.get('type', 'Unknown'),
                                'patterns': {},
                                'total_values': total_values,
                                'privacy_count': privacy_count,
                                'privacy_ratio': privacy_ratio,
                                'risk_score': table_data.get('privacy_score', 0),
                                'sample_values': sample_values,
                                'table_rows': table_data.get('sampling_info', {}).get('total_rows', 0)
                            }
                        
                        for pattern_type, match_count in matches.items():
                            if pattern_type not in privacy_columns_summary[key]['patterns']:
                                privacy_columns_summary[key]['patterns'][pattern_type] = 0
                            privacy_columns_summary[key]['patterns'][pattern_type] += match_count
                    
                    # ì˜ì‹¬ìŠ¤ëŸ¬ìš´ ì»¬ëŸ¼ëª…
                    elif col_data.get('suspicious_name'):
                        key = f"{full_table_name}.{col_name}"
                        suspicious_columns_summary[key] = {
                            'database': db_name,
                            'table': table_name,
                            'column': col_name,
                            'column_type': col_data.get('type', 'Unknown'),
                            'reason': 'ì˜ì‹¬ìŠ¤ëŸ¬ìš´ ì»¬ëŸ¼ëª…',
                            'risk_score': table_data.get('privacy_score', 0),
                            'table_rows': table_data.get('sampling_info', {}).get('total_rows', 0)
                        }
        
        # ê°œì¸ì •ë³´ íŒ¨í„´ì´ ë°œê²¬ëœ ì»¬ëŸ¼ë“¤
        if privacy_columns_summary:
            report.append("ğŸš¨ ê°œì¸ì •ë³´ íŒ¨í„´ì´ ë°œê²¬ëœ ì»¬ëŸ¼ë“¤:")
            report.append("")
            
            # ìœ„í—˜ë„ ìˆœìœ¼ë¡œ ì •ë ¬
            sorted_privacy_columns = sorted(
                privacy_columns_summary.items(), 
                key=lambda x: x[1]['risk_score'], 
                reverse=True
            )
            
            for i, (col_key, col_info) in enumerate(sorted_privacy_columns, 1):
                report.append(f"  {i:2d}. ğŸ“‹ ì»¬ëŸ¼: {col_info['database']}.{col_info['table']}.{col_info['column']}")
                report.append(f"      ğŸ“Š ë°ì´í„° íƒ€ì…: {col_info['column_type']}")
                report.append(f"      ğŸ“ˆ í…Œì´ë¸” ì´ í–‰ìˆ˜: {col_info['table_rows']:,}í–‰")
                report.append(f"      ğŸ“ˆ ìŠ¤ìº”ëœ ë°ì´í„°: {col_info['total_values']:,}ê±´")
                report.append(f"      âš ï¸  ê°œì¸ì •ë³´ ë°œê²¬: {col_info['privacy_count']:,}ê±´ ({col_info['privacy_ratio']:.1%})")
                report.append(f"      ğŸ¯ ìœ„í—˜ë„ ì ìˆ˜: {col_info['risk_score']}")
                
                # íŒ¨í„´ë³„ ìƒì„¸
                pattern_details = []
                for pattern_type, count in col_info['patterns'].items():
                    pattern_details.append(f"{pattern_type}({count}ê±´)")
                report.append(f"      â€¢ ë°œê²¬ëœ íŒ¨í„´: {', '.join(pattern_details)}")
                
                # ìƒ˜í”Œ ë°ì´í„° í‘œì‹œ
                if col_info['sample_values']:
                    report.append(f"      ğŸ“ ìƒ˜í”Œ ë°ì´í„°:")
                    for j, sample in enumerate(col_info['sample_values'][:3], 1):
                        report.append(f"         {j}. {sample}")
                    if len(col_info['sample_values']) > 3:
                        report.append(f"         ... ì™¸ {len(col_info['sample_values']) - 3}ê°œ")
                
                report.append("")
        else:
            report.append("âœ… ê°œì¸ì •ë³´ íŒ¨í„´ì´ ë°œê²¬ëœ ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.")
            report.append("")
        
        # ì˜ì‹¬ìŠ¤ëŸ¬ìš´ ì»¬ëŸ¼ëª…ë“¤
        if suspicious_columns_summary:
            report.append("âš ï¸  ì˜ì‹¬ìŠ¤ëŸ¬ìš´ ì»¬ëŸ¼ëª…ë“¤:")
            report.append("")
            
            sorted_suspicious = sorted(
                suspicious_columns_summary.items(),
                key=lambda x: x[1]['risk_score'],
                reverse=True
            )
            
            for i, (col_key, col_info) in enumerate(sorted_suspicious, 1):
                report.append(f"  {i:2d}. ğŸ“‹ ì»¬ëŸ¼: {col_info['database']}.{col_info['table']}.{col_info['column']}")
                report.append(f"      ğŸ“Š ë°ì´í„° íƒ€ì…: {col_info['column_type']}")
                report.append(f"      ğŸ“ˆ í…Œì´ë¸” ì´ í–‰ìˆ˜: {col_info['table_rows']:,}í–‰")
                report.append(f"      ğŸ¯ ìœ„í—˜ë„ ì ìˆ˜: {col_info['risk_score']}")
                report.append(f"      âš ï¸  ì˜ì‹¬ ì‚¬ìœ : {col_info['reason']}")
                report.append("")
        else:
            report.append("âœ… ì˜ì‹¬ìŠ¤ëŸ¬ìš´ ì»¬ëŸ¼ëª…ì´ ì—†ìŠµë‹ˆë‹¤.")
            report.append("")
        
        # ë°ì´í„°ë² ì´ìŠ¤ë³„ ìš”ì•½
        db_summary = {}
        for db_result in scan_results:
            db_name = db_result.get('database', 'Unknown')
            db_summary[db_name] = {
                'tables': 0,
                'high_risk_tables': 0,
                'medium_risk_tables': 0,
                'privacy_columns': 0,
                'suspicious_columns': 0,
                'total_score': 0
            }
            
            for table_name, table_data in db_result.get('tables', {}).items():
                db_summary[db_name]['tables'] += 1
                risk_level = table_data.get('risk_level', 'LOW')
                
                if risk_level == 'HIGH':
                    db_summary[db_name]['high_risk_tables'] += 1
                elif risk_level == 'MEDIUM':
                    db_summary[db_name]['medium_risk_tables'] += 1
                
                db_summary[db_name]['total_score'] += table_data.get('privacy_score', 0)
                
                for col_name, col_data in table_data.get('columns', {}).items():
                    pattern_scan = col_data.get('pattern_scan', {})
                    if pattern_scan and 'privacy_matches' in pattern_scan and pattern_scan['privacy_matches']:
                        db_summary[db_name]['privacy_columns'] += 1
                    elif col_data.get('suspicious_name'):
                        db_summary[db_name]['suspicious_columns'] += 1
        
        if len(db_summary) > 1:
            report.append("ğŸ—„ï¸  ë°ì´í„°ë² ì´ìŠ¤ë³„ ìš”ì•½:")
            report.append("")
            
            for db_name, stats in sorted(db_summary.items(), key=lambda x: x[1]['total_score'], reverse=True):
                report.append(f"  ğŸ“Š {db_name}:")
                report.append(f"      â€¢ í…Œì´ë¸” ìˆ˜: {stats['tables']}ê°œ")
                report.append(f"      â€¢ ê³ ìœ„í—˜ í…Œì´ë¸”: {stats['high_risk_tables']}ê°œ")
                report.append(f"      â€¢ ì¤‘ê°„ìœ„í—˜ í…Œì´ë¸”: {stats['medium_risk_tables']}ê°œ")
                report.append(f"      â€¢ ê°œì¸ì •ë³´ ì»¬ëŸ¼: {stats['privacy_columns']}ê°œ")
                report.append(f"      â€¢ ì˜ì‹¬ ì»¬ëŸ¼: {stats['suspicious_columns']}ê°œ")
                report.append(f"      â€¢ ì´ ìœ„í—˜ë„ ì ìˆ˜: {stats['total_score']}")
                report.append("")
        
        # íŒ¨í„´ë³„ í†µê³„
        pattern_stats = {}
        for col_info in privacy_columns_summary.values():
            for pattern_type, count in col_info['patterns'].items():
                if pattern_type not in pattern_stats:
                    pattern_stats[pattern_type] = {
                        'total_matches': 0,
                        'columns_count': 0,
                        'databases': set(),
                        'tables': set()
                    }
                pattern_stats[pattern_type]['total_matches'] += count
                pattern_stats[pattern_type]['columns_count'] += 1
                pattern_stats[pattern_type]['databases'].add(col_info['database'])
                pattern_stats[pattern_type]['tables'].add(f"{col_info['database']}.{col_info['table']}")
        
        if pattern_stats:
            report.append("ğŸ“ˆ íŒ¨í„´ë³„ ë°œê²¬ í†µê³„:")
            report.append("")
            
            for pattern_type, stats in sorted(pattern_stats.items()):
                report.append(f"  â€¢ {pattern_type}:")
                report.append(f"      â€¢ ì´ ë°œê²¬ ê±´ìˆ˜: {stats['total_matches']:,}ê±´")
                report.append(f"      â€¢ ë°œê²¬ëœ ì»¬ëŸ¼ ìˆ˜: {stats['columns_count']}ê°œ")
                report.append(f"      â€¢ ê´€ë ¨ í…Œì´ë¸” ìˆ˜: {len(stats['tables'])}ê°œ")
                report.append(f"      â€¢ ê´€ë ¨ ë°ì´í„°ë² ì´ìŠ¤: {len(stats['databases'])}ê°œ")
                report.append("")
        
        # ê¶Œì¥ì‚¬í•­
        report.append("ğŸ’¡ ê¶Œì¥ì‚¬í•­:")
        
        if privacy_columns_summary:
            report.append("  â€¢ ê°œì¸ì •ë³´ê°€ ë°œê²¬ëœ ì»¬ëŸ¼ë“¤ì„ ìš°ì„ ì ìœ¼ë¡œ ê²€í† í•˜ì„¸ìš”.")
            report.append("  â€¢ ë°œê²¬ëœ ê°œì¸ì •ë³´ì˜ ì ì ˆí•œ ì•”í˜¸í™” ë˜ëŠ” ë§ˆìŠ¤í‚¹ì„ ê³ ë ¤í•˜ì„¸ìš”.")
            report.append("  â€¢ GDPR/ê°œì¸ì •ë³´ë³´í˜¸ë²• ì¤€ìˆ˜ ì—¬ë¶€ë¥¼ ì ê²€í•˜ì„¸ìš”.")
        
        if suspicious_columns_summary:
            report.append("  â€¢ ì˜ì‹¬ìŠ¤ëŸ¬ìš´ ì»¬ëŸ¼ëª…ì„ ê°€ì§„ í…Œì´ë¸”ë“¤ì„ ì¶”ê°€ë¡œ ê²€í† í•˜ì„¸ìš”.")
        
        if total_high_risk > 0:
            report.append("  â€¢ ê³ ìœ„í—˜ í…Œì´ë¸”ë“¤ì— ëŒ€í•œ ì¦‰ì‹œ ì¡°ì¹˜ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
        
        report.append("  â€¢ ì •ê¸°ì ì¸ ê°œì¸ì •ë³´ ìŠ¤ìº”ì„ í†µí•´ ì§€ì†ì ì¸ ëª¨ë‹ˆí„°ë§ì„ ìˆ˜í–‰í•˜ì„¸ìš”.")
        
        return "\n".join(report)

    def save_results_with_summary(self, results: List[Dict], timestamp: str) -> None:
        """ê²°ê³¼ë¥¼ JSONìœ¼ë¡œ ì €ì¥í•˜ê³  ìš”ì•½ ë¦¬í¬íŠ¸ ìƒì„±"""
        # JSON íŒŒì¼ ì €ì¥
        scan_filename = f"polars_privacy_scan_{timestamp}.json"
        with open(scan_filename, "w", encoding="utf-8") as f:
            json.dump(results, f, ensure_ascii=False, indent=2)
        
        print(f"ğŸ’¾ ìŠ¤ìº” ê²°ê³¼ê°€ {scan_filename}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
        
        # ìš”ì•½ ë¦¬í¬íŠ¸ ìƒì„± ë° ì¶œë ¥
        summary_report = self.generate_privacy_summary_report(results)
        print("\n" + summary_report)
        
        # ìš”ì•½ ë¦¬í¬íŠ¸ë„ íŒŒì¼ë¡œ ì €ì¥
        summary_filename = f"privacy_scan_summary_{timestamp}.txt"
        with open(summary_filename, "w", encoding="utf-8") as f:
            f.write(summary_report)
        
        print(f"ğŸ“„ ìš”ì•½ ë¦¬í¬íŠ¸ê°€ {summary_filename}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

    def is_system_schema(self, database_name: str) -> bool:
        """ì‹œìŠ¤í…œ ìŠ¤í‚¤ë§ˆì¸ì§€ í™•ì¸"""
        # ì •í™•í•œ ë§¤ì¹­
        if database_name.lower() in self.system_schemas:
            return True
        
        # íŒ¨í„´ ë§¤ì¹­ (ì‹œìŠ¤í…œ ê´€ë ¨ ì ‘ë‘ì‚¬/ì ‘ë¯¸ì‚¬)
        db_lower = database_name.lower()
        
        # ì‹œìŠ¤í…œ ê´€ë ¨ ì ‘ë‘ì‚¬
        system_prefixes = ['sys_', 'system_', 'mysql_', 'info_', 'perf_', 'audit_', 'log_', 'monitor_', 'temp_', 'backup_']
        for prefix in system_prefixes:
            if db_lower.startswith(prefix):
                return True
        
        # ì‹œìŠ¤í…œ ê´€ë ¨ ì ‘ë¯¸ì‚¬
        system_suffixes = ['_sys', '_system', '_temp', '_tmp', '_backup', '_log', '_audit', '_monitor', '_test']
        for suffix in system_suffixes:
            if db_lower.endswith(suffix):
                return True
        
        # ìˆ«ìë§Œìœ¼ë¡œ êµ¬ì„±ëœ ìŠ¤í‚¤ë§ˆ (ì¼ë°˜ì ìœ¼ë¡œ ì‹œìŠ¤í…œìš©)
        if database_name.isdigit():
            return True
        
        return False

    def get_user_databases(self) -> List[str]:
        """ì‚¬ìš©ì ë°ì´í„°ë² ì´ìŠ¤ ëª©ë¡ ì¡°íšŒ (ì‹œìŠ¤í…œ ìŠ¤í‚¤ë§ˆ ì œì™¸)"""
        all_databases = self.get_databases()
        user_databases = []
        system_databases = []
        
        for db in all_databases:
            if self.is_system_schema(db):
                system_databases.append(db)
            else:
                user_databases.append(db)
        
        # ì œì™¸ëœ ì‹œìŠ¤í…œ ìŠ¤í‚¤ë§ˆ ì •ë³´ ì¶œë ¥
        if system_databases:
            print(f"ğŸ”’ ì‹œìŠ¤í…œ ìŠ¤í‚¤ë§ˆ ì œì™¸ë¨ ({len(system_databases)}ê°œ):")
            for i, sys_db in enumerate(sorted(system_databases), 1):
                print(f"   {i:2d}. {sys_db}")
            print("")
        
        return user_databases

    def preview_all_databases(self) -> List[Dict]:
        """ëª¨ë“  ë°ì´í„°ë² ì´ìŠ¤ êµ¬ì¡° ë¶„ì„ ë° ì²˜ë¦¬ ë¹„ìš© ì˜ˆì¸¡"""
        if not self.connect():
            return []

        try:
            user_databases = self.get_user_databases()

            print(f"ğŸ¯ ë°œê²¬ëœ ì‚¬ìš©ì ë°ì´í„°ë² ì´ìŠ¤: {len(user_databases)}ê°œ")
            print(f"âš¡ ë¶„ì„ ì—”ì§„: Polars")
            print(f"ğŸ“Š ìƒ˜í”Œë§ ì„¤ì •: í…Œì´ë¸”ë‹¹ ìµœëŒ€ {self.sample_size}ê±´")
            print("=" * 60)

            all_analyses = []
            total_start_time = datetime.now()

            for i, database in enumerate(user_databases, 1):
                print(f"\n[{i}/{len(user_databases)}] ë°ì´í„°ë² ì´ìŠ¤ êµ¬ì¡° ë¶„ì„ ì¤‘...")

                analysis_start_time = datetime.now()
                analysis = self.analyze_database_structure(database)
                analysis_end_time = datetime.now()

                analysis['analysis_duration'] = str(analysis_end_time - analysis_start_time)
                all_analyses.append(analysis)

                print(self.generate_structure_report(analysis))
                print(f"â±ï¸  ë¶„ì„ ì‹œê°„: {analysis_end_time - analysis_start_time}")
                print("\n" + "=" * 80 + "\n")

            total_end_time = datetime.now()
            self.generate_total_preview_summary(all_analyses, total_end_time - total_start_time)

            return all_analyses

        finally:
            self.disconnect()

    def scan_all_databases(self) -> List[Dict]:
        """ëª¨ë“  ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤ìº” (ì‹¤ì œ ê°œì¸ì •ë³´ íƒì§€)"""
        if not self.connect():
            return []

        try:
            user_databases = self.get_user_databases()

            print(f"ğŸ¯ ë°œê²¬ëœ ì‚¬ìš©ì ë°ì´í„°ë² ì´ìŠ¤: {len(user_databases)}ê°œ")
            print(f"âš¡ ì²˜ë¦¬ ì—”ì§„: Polars")
            print(f"ğŸ“Š ìƒ˜í”Œë§: í…Œì´ë¸”ë‹¹ ìµœëŒ€ {self.sample_size}ê±´")
            print("=" * 60)

            all_results = []
            total_start_time = datetime.now()

            for i, database in enumerate(user_databases, 1):
                print(f"\n[{i}/{len(user_databases)}] ë°ì´í„°ë² ì´ìŠ¤ ì²˜ë¦¬ ì¤‘...")

                db_start_time = datetime.now()
                result = self.scan_database(database)
                db_end_time = datetime.now()

                result['processing_time'] = str(db_end_time - db_start_time)
                all_results.append(result)

                print(self.generate_scan_report(result))
                print(f"â±ï¸  ì²˜ë¦¬ ì‹œê°„: {db_end_time - db_start_time}")
                print("\n" + "=" * 80 + "\n")

            total_end_time = datetime.now()
            print(f"ğŸ‰ ì „ì²´ ìŠ¤ìº” ì™„ë£Œ! (Polars ì—”ì§„)")
            print(f"â±ï¸  ì´ ì²˜ë¦¬ ì‹œê°„: {total_end_time - total_start_time}")

            return all_results

        finally:
            self.disconnect()

    def scan_all_databases_with_progress(self):
        """ì§„í–‰ë¥  í‘œì‹œì™€ í•¨ê»˜ ëª¨ë“  ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤ìº”"""
        if not self.connect():
            return []
        
        try:
            user_databases = self.get_user_databases()
            results = []
            
            with tqdm(total=len(user_databases), desc="ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤ìº”") as pbar:
                for database in user_databases:
                    result = self.scan_database(database)
                    results.append(result)
                    pbar.update(1)
                    pbar.set_postfix({'í˜„ì¬': database})
            
            return results
        finally:
            self.disconnect()

    def generate_total_preview_summary(self, all_analyses: List[Dict], total_time) -> None:
        """ì „ì²´ ë°ì´í„°ë² ì´ìŠ¤ ì˜ˆì¸¡ ìš”ì•½"""
        print("ğŸ¯ ì „ì²´ ë°ì´í„°ë² ì´ìŠ¤ ì²˜ë¦¬ ë¹„ìš© ì˜ˆì¸¡ ìš”ì•½ (Polars)")
        print("=" * 60)

        total_tables = sum(a.get('summary', {}).get('total_tables', 0) for a in all_analyses)
        total_rows = sum(a.get('summary', {}).get('total_rows', 0) for a in all_analyses)
        total_columns = sum(a.get('summary', {}).get('total_columns', 0) for a in all_analyses)
        total_mb = sum(a.get('summary', {}).get('estimated_total_mb', 0) for a in all_analyses)
        total_scan_time = sum(a.get('summary', {}).get('estimated_total_scan_time_sec', 0) for a in all_analyses)
        scannable_tables = sum(a.get('summary', {}).get('scannable_tables', 0) for a in all_analyses)
        large_tables = sum(a.get('summary', {}).get('large_tables', 0) for a in all_analyses)

        print(f"ğŸ“Š ì „ì²´ ê·œëª¨:")
        print(f"  â€¢ ë°ì´í„°ë² ì´ìŠ¤ ìˆ˜: {len(all_analyses)}ê°œ")
        print(f"  â€¢ ì´ í…Œì´ë¸” ìˆ˜: {total_tables:,}ê°œ")
        print(f"  â€¢ ìŠ¤ìº” ê°€ëŠ¥í•œ í…Œì´ë¸”: {scannable_tables:,}ê°œ")
        print(f"  â€¢ ëŒ€ìš©ëŸ‰ í…Œì´ë¸” (100ë§Œí–‰+): {large_tables:,}ê°œ")
        print(f"  â€¢ ì´ ë°ì´í„° í–‰ ìˆ˜: {total_rows:,}í–‰")
        print(f"  â€¢ ì´ ì»¬ëŸ¼ ìˆ˜: {total_columns:,}ê°œ")

        print(f"\nğŸ’¾ ì˜ˆìƒ ì²˜ë¦¬ ë¹„ìš© (Polars ì—”ì§„):")
        print(f"  â€¢ ì˜ˆìƒ ì´ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: {total_mb:.1f} MB")
        print(f"  â€¢ ì˜ˆìƒ ì´ ìŠ¤ìº” ì‹œê°„: {total_scan_time:.1f}ì´ˆ")

        if total_scan_time > 60:
            minutes = int(total_scan_time // 60)
            seconds = int(total_scan_time % 60)
            print(f"    â†’ {minutes}ë¶„ {seconds}ì´ˆ")

        print(f"\nğŸš¦ ì²˜ë¦¬ ìœ„í—˜ë„ í‰ê°€:")

        memory_risk = "ğŸŸ¢ ë‚®ìŒ" if total_mb < 100 else "ğŸŸ¡ ë³´í†µ" if total_mb < 500 else "ğŸ”´ ë†’ìŒ"
        time_risk = "ğŸŸ¢ ë¹ ë¦„" if total_scan_time < 60 else "ğŸŸ¡ ë³´í†µ" if total_scan_time < 600 else "ğŸ”´ ì˜¤ë˜ ê±¸ë¦¼"

        print(f"  â€¢ ë©”ëª¨ë¦¬ ìœ„í—˜ë„: {memory_risk} ({total_mb:.1f} MB)")
        print(f"  â€¢ ì‹œê°„ ìœ„í—˜ë„: {time_risk} ({total_scan_time:.1f}ì´ˆ)")

        if large_tables > 20:
            print(f"  â€¢ ëŒ€ìš©ëŸ‰ í…Œì´ë¸” ìœ„í—˜ë„: ğŸ”´ ë†’ìŒ ({large_tables}ê°œ)")
        elif large_tables > 5:
            print(f"  â€¢ ëŒ€ìš©ëŸ‰ í…Œì´ë¸” ìœ„í—˜ë„: ğŸŸ¡ ë³´í†µ ({large_tables}ê°œ)")
        else:
            print(f"  â€¢ ëŒ€ìš©ëŸ‰ í…Œì´ë¸” ìœ„í—˜ë„: ğŸŸ¢ ë‚®ìŒ ({large_tables}ê°œ)")

        print(f"\nâ±ï¸  ì „ì²´ ë¶„ì„ ì‹œê°„: {total_time}")
        print(f"ğŸš€ Polars ì—”ì§„ìœ¼ë¡œ ìµœì í™”ëœ ì²˜ë¦¬ ì¤€ë¹„ ì™„ë£Œ!")

        print(f"\nğŸ’¡ ìŠ¤ìº” ì‹¤í–‰ ê¶Œì¥ì‚¬í•­:")

        if total_mb > 1000:
            print(f"  âš ï¸  ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì´ ë†’ìŠµë‹ˆë‹¤ ({total_mb:.1f}MB)")
            print(f"     â†’ ìƒ˜í”Œ í¬ê¸°ë¥¼ 50ìœ¼ë¡œ ì¤„ì´ê±°ë‚˜ ë°ì´í„°ë² ì´ìŠ¤ë³„ë¡œ ë¶„í•  ì‹¤í–‰í•˜ì„¸ìš”")

        if total_scan_time > 1800:
            print(f"  âš ï¸  ì˜ˆìƒ ì²˜ë¦¬ ì‹œê°„ì´ ê¹ë‹ˆë‹¤ ({total_scan_time / 60:.1f}ë¶„)")
            print(f"     â†’ ëŒ€ìš©ëŸ‰ í…Œì´ë¸”ì„ ì œì™¸í•˜ê±°ë‚˜ ë°°ì¹˜ë¡œ ë‚˜ëˆ„ì–´ ì‹¤í–‰í•˜ì„¸ìš”")

        if large_tables > 50:
            print(f"  âš ï¸  ëŒ€ìš©ëŸ‰ í…Œì´ë¸”ì´ ë§ìŠµë‹ˆë‹¤ ({large_tables}ê°œ)")
            print(f"     â†’ ìš°ì„ ìˆœìœ„ê°€ ë†’ì€ í…Œì´ë¸”ë¶€í„° ì„ ë³„ì ìœ¼ë¡œ ìŠ¤ìº”í•˜ì„¸ìš”")

        if total_tables > 1000:
            print(f"  âš ï¸  í…Œì´ë¸” ìˆ˜ê°€ ë§ìŠµë‹ˆë‹¤ ({total_tables:,}ê°œ)")
            print(f"     â†’ ì¤‘ìš”í•œ ë°ì´í„°ë² ì´ìŠ¤ë¶€í„° ë‹¨ê³„ì ìœ¼ë¡œ ìŠ¤ìº”í•˜ì„¸ìš”")

        print(f"\nâœ… êµ¬ì¡° ë¶„ì„ ì™„ë£Œ! ì´ì œ ì‹¤ì œ ìŠ¤ìº”ì„ ì‹¤í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        print("=" * 60)


# ì‚¬ìš© ì˜ˆì‹œ
if __name__ == "__main__":
    # .env íŒŒì¼ ë¡œë“œ (ìˆëŠ” ê²½ìš°)
    load_dotenv()
    
    # Polars ê¸°ë°˜ ìŠ¤ìºë„ˆ ì´ˆê¸°í™” (ë¹„ë°€ë²ˆí˜¸ ì—†ì´ë„ ê°€ëŠ¥)
    scanner = PolarsPrivacyScanner(
        host="localhost",
        user="root",
        # password="fosslight",  # ë¹„ë°€ë²ˆí˜¸ ì—†ì´ë„ ì ‘ì† ê°€ëŠ¥
        port=9030,
        sample_size=100
    )

    print("ğŸš€ Polars ê¸°ë°˜ MySQL ê°œì¸ì •ë³´ ìŠ¤ìºë„ˆ")
    print("ğŸ“¦ í™˜ê²½ ì„¤ì •:")
    print("   uv venv privacy-scanner")
    print("   source privacy-scanner/bin/activate  # Linux/Mac")
    print("   # privacy-scanner\\Scripts\\activate  # Windows")
    print("   uv add polars mysql-connector-python")
    print("=" * 60)
    print("ìë™ ì‹¤í–‰ ìˆœì„œ: êµ¬ì¡° ë¶„ì„ â†’ ë¹„ìš© ì˜ˆì¸¡ â†’ ê°œì¸ì •ë³´ ìŠ¤ìº”")
    print("=" * 60)

    # ì—°ê²° ì •ë³´ ì¶œë ¥
    print(f"ğŸ”— ì—°ê²° ì •ë³´:")
    print(f"   â€¢ í˜¸ìŠ¤íŠ¸: {scanner.host}:{scanner.port}")
    print(f"   â€¢ ì‚¬ìš©ì: {scanner.user}")
    if scanner.password:
        print(f"   â€¢ ì¸ì¦: ì‚¬ìš©ìëª… + ë¹„ë°€ë²ˆí˜¸")
    else:
        print(f"   â€¢ ì¸ì¦: ì‚¬ìš©ìëª…ë§Œ (ë¹„ë°€ë²ˆí˜¸ ì—†ìŒ)")
    print(f"   â€¢ ìƒ˜í”Œ í¬ê¸°: {scanner.sample_size}ê±´")
    print("=" * 60)

    try:
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')

        # 1ë‹¨ê³„: ë°ì´í„°ë² ì´ìŠ¤ êµ¬ì¡° ë¶„ì„
        print("\nğŸ” 1ë‹¨ê³„: ë°ì´í„°ë² ì´ìŠ¤ êµ¬ì¡° ë¶„ì„ ì‹œì‘...")
        analyses = scanner.preview_all_databases()

        analysis_filename = f"polars_db_analysis_{timestamp}.json"
        with open(analysis_filename, "w", encoding="utf-8") as f:
            json.dump(analyses, f, ensure_ascii=False, indent=2)

        print(f"\nğŸ’¾ êµ¬ì¡° ë¶„ì„ ê²°ê³¼ê°€ {analysis_filename}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

        # 2ë‹¨ê³„: ì‚¬ìš©ì í™•ì¸ (ìë™ ì§„í–‰)
        print("\nâ³ 3ì´ˆ í›„ ê°œì¸ì •ë³´ ìŠ¤ìº”ì„ ìë™ìœ¼ë¡œ ì‹œì‘í•©ë‹ˆë‹¤...")
        import time
        time.sleep(3)

        # 3ë‹¨ê³„: ê°œì¸ì •ë³´ ìŠ¤ìº” ì‹¤í–‰
        print("\nğŸš€ 2ë‹¨ê³„: ê°œì¸ì •ë³´ ìŠ¤ìº” ì‹¤í–‰...")
        results = scanner.scan_all_databases()

        # 4ë‹¨ê³„: ê²°ê³¼ ì €ì¥ ë° ìš”ì•½ ë¦¬í¬íŠ¸ ìƒì„±
        scanner.save_results_with_summary(results, timestamp)

        print(f"\nâœ… ì „ì²´ í”„ë¡œì„¸ìŠ¤ ì™„ë£Œ!")
        print(f"ğŸ“„ êµ¬ì¡° ë¶„ì„: {analysis_filename}")
        print(f"ğŸ“„ ìŠ¤ìº” ê²°ê³¼: polars_privacy_scan_{timestamp}.json")
        print(f"ğŸ“„ ìš”ì•½ ë¦¬í¬íŠ¸: privacy_scan_summary_{timestamp}.txt")

    except KeyboardInterrupt:
        print("\n\nâš ï¸  ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")

    print("\nğŸ‘‹ í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")