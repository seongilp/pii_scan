import cx_Oracle
import polars as pl
import re
import json
from typing import Dict, List, Tuple, Any, Optional
from datetime import datetime
import warnings

warnings.filterwarnings('ignore')


class OraclePrivacyScanner:
    def __init__(self, host: str, port: int, service_name: str, user: str, password: str,
                 sample_size: int = 100):
        """
        Oracle ê¸°ë°˜ ê°œì¸ì •ë³´ ìŠ¤ìºë„ˆ

        Args:
            host: Oracle ì„œë²„ í˜¸ìŠ¤íŠ¸
            port: Oracle í¬íŠ¸ (ê¸°ë³¸ 1521)
            service_name: Oracle ì„œë¹„ìŠ¤ëª… ë˜ëŠ” SID
            user: ì‚¬ìš©ìëª…
            password: ë¹„ë°€ë²ˆí˜¸
            sample_size: ìƒ˜í”Œë§í•  í–‰ ìˆ˜
        """
        self.host = host
        self.port = port
        self.service_name = service_name
        self.user = user
        self.password = password
        self.connection = None
        self.sample_size = sample_size

        # Oracle ì—°ê²° ë¬¸ìì—´ ìƒì„±
        self.dsn = cx_Oracle.makedsn(host, port, service_name=service_name)

        # ê°œì¸ì •ë³´ íŒ¨í„´ ì •ì˜ - í•œêµ­ í˜•ì‹ìœ¼ë¡œ ì—…ë°ì´íŠ¸
        self.privacy_patterns = {
            'email': r'\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b',
            'phone': r'(\d{2,3}-\d{3,4}-\d{4}|\d{10,11})',
            'ssn': r'\d{6}-[1-4]\d{6}',  # í•œêµ­ ì£¼ë¯¼ë“±ë¡ë²ˆí˜¸ í˜•ì‹
            'card_number': r'5327-\d{4}-\d{4}-\d{4}',  # 5327ë¡œ ì‹œì‘í•˜ëŠ” 16ìë¦¬ ì¹´ë“œë²ˆí˜¸
            'account_number': r'1000-\d{8}',  # 1000ìœ¼ë¡œ ì‹œì‘í•˜ëŠ” 12ìë¦¬ ê³„ì¢Œë²ˆí˜¸
            'ip_address': r'\b(?:[0-9]{1,3}\.){3}[0-9]{1,3}\b',
        }

        # ê°œì¸ì •ë³´ ê´€ë ¨ ì»¬ëŸ¼ëª… í‚¤ì›Œë“œ
        self.privacy_keywords = [
            'name', 'email', 'phone', 'mobile', 'tel', 'address', 'addr',
            'ssn', 'social', 'birth', 'birthday', 'card', 'account',
            'ì´ë¦„', 'ì„±ëª…', 'ì „í™”', 'íœ´ëŒ€í°', 'ì£¼ì†Œ', 'ì£¼ë¯¼', 'ìƒë…„ì›”ì¼', 'ì¹´ë“œ', 'ê³„ì¢Œ',
            'user_id', 'customer', 'ê³ ê°', 'personal', 'ê°œì¸', 'emp_id', 'employee'
        ]

        print(f"ğŸ”® Oracle ê¸°ë°˜ ê°œì¸ì •ë³´ ìŠ¤ìºë„ˆ ì´ˆê¸°í™”")
        print(f"   Host: {host}:{port}")
        print(f"   Service: {service_name}")
        print(f"   User: {user}")
        print(f"   ìƒ˜í”Œ í¬ê¸°: {sample_size}ê±´")

    def connect(self):
        """Oracle ì—°ê²°"""
        try:
            self.connection = cx_Oracle.connect(
                user=self.user,
                password=self.password,
                dsn=self.dsn,
                encoding="UTF-8"
            )
            print(f"âœ… Oracle ì—°ê²° ì„±ê³µ: {self.host}:{self.port}/{self.service_name}")
            return True
        except cx_Oracle.Error as err:
            print(f"âŒ Oracle ì—°ê²° ì‹¤íŒ¨: {err}")
            return False

    def disconnect(self):
        """Oracle ì—°ê²° í•´ì œ"""
        if self.connection:
            self.connection.close()
            print("ğŸ” Oracle ì—°ê²° í•´ì œ")

    def get_schemas(self) -> List[str]:
        """ëª¨ë“  ìŠ¤í‚¤ë§ˆ ëª©ë¡ ì¡°íšŒ (ì‚¬ìš©ì ì†Œìœ )"""
        cursor = self.connection.cursor()

        # í˜„ì¬ ì‚¬ìš©ìê°€ ì ‘ê·¼ ê°€ëŠ¥í•œ ìŠ¤í‚¤ë§ˆ ì¡°íšŒ
        cursor.execute("""
                       SELECT DISTINCT OWNER
                       FROM ALL_TABLES
                       WHERE OWNER NOT IN ('SYS', 'SYSTEM', 'OUTLN', 'DBSNMP', 'APPQOSSYS',
                                           'WMSYS', 'EXFSYS', 'CTXSYS', 'XDB', 'ANONYMOUS',
                                           'OLAPSYS', 'MDSYS', 'ORDSYS', 'FLOWS_FILES',
                                           'APEX_030200', 'APEX_PUBLIC_USER', 'SPATIAL_CSW_ADMIN_USR',
                                           'SPATIAL_WFS_ADMIN_USR', 'PUBLIC')
                       ORDER BY OWNER
                       """)

        schemas = [row[0] for row in cursor.fetchall()]
        cursor.close()
        return schemas

    def get_tables(self, schema: str) -> List[str]:
        """íŠ¹ì • ìŠ¤í‚¤ë§ˆì˜ í…Œì´ë¸” ëª©ë¡ ì¡°íšŒ"""
        cursor = self.connection.cursor()

        cursor.execute("""
                       SELECT TABLE_NAME
                       FROM ALL_TABLES
                       WHERE OWNER = :schema
                       ORDER BY TABLE_NAME
                       """, schema=schema)

        tables = [row[0] for row in cursor.fetchall()]
        cursor.close()
        return tables

    def get_table_info(self, schema: str, table: str) -> Dict:
        """í…Œì´ë¸” ì •ë³´ ì¡°íšŒ (í–‰ ìˆ˜, ì»¬ëŸ¼ ì •ë³´)"""
        cursor = self.connection.cursor()

        # í–‰ ìˆ˜ ì¡°íšŒ
        try:
            cursor.execute(f"SELECT COUNT(*) FROM {schema}.{table}")
            total_rows = cursor.fetchone()[0]
        except Exception as e:
            print(f"    âš ï¸  í–‰ ìˆ˜ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")
            total_rows = 0

        # ì»¬ëŸ¼ ì •ë³´ ì¡°íšŒ
        cursor.execute("""
                       SELECT COLUMN_NAME, DATA_TYPE, NULLABLE, DATA_LENGTH, DATA_PRECISION, DATA_SCALE
                       FROM ALL_TAB_COLUMNS
                       WHERE OWNER = :schema
                         AND TABLE_NAME = :table
                       ORDER BY COLUMN_ID
                       """, schema=schema, table=table)

        columns = []
        for row in cursor.fetchall():
            columns.append({
                'name': row[0],
                'type': row[1],
                'nullable': row[2],
                'length': row[3],
                'precision': row[4],
                'scale': row[5]
            })

        cursor.close()
        return {
            'total_rows': total_rows,
            'columns': columns
        }

    def estimate_dataframe_size(self, columns: List[Dict], sample_rows: int) -> Dict:
        """DataFrame ì˜ˆìƒ í¬ê¸° ê³„ì‚° (Oracle íƒ€ì… ê¸°ì¤€)"""
        size_estimates = {
            'NUMBER': 8, 'INTEGER': 8, 'FLOAT': 8,
            'VARCHAR2': 50, 'CHAR': 20, 'CLOB': 500, 'LONG': 200,
            'DATE': 8, 'TIMESTAMP': 12, 'TIMESTAMP(6)': 12,
            'RAW': 50, 'BLOB': 500, 'LONG RAW': 200
        }

        total_bytes_per_row = 0
        text_columns = 0
        numeric_columns = 0
        date_columns = 0

        for col in columns:
            col_type = col['type'].upper()
            col_size = 8  # ê¸°ë³¸ê°’

            # Oracle íƒ€ì…ë³„ í¬ê¸° ì¶”ì •
            if col_type in size_estimates:
                col_size = size_estimates[col_type]
            elif col_type.startswith('VARCHAR2'):
                # VARCHAR2(n) ì²˜ë¦¬
                col_size = min(col.get('length', 50), 255)
                text_columns += 1
            elif col_type.startswith('CHAR'):
                col_size = min(col.get('length', 20), 255)
                text_columns += 1
            elif col_type in ['CLOB', 'LONG']:
                text_columns += 1
            elif col_type in ['NUMBER', 'INTEGER', 'FLOAT']:
                numeric_columns += 1
            elif col_type in ['DATE', 'TIMESTAMP'] or col_type.startswith('TIMESTAMP'):
                date_columns += 1

            total_bytes_per_row += col_size

        overhead_factor = 1.3
        estimated_size_bytes = total_bytes_per_row * sample_rows * overhead_factor

        return {
            'total_columns': len(columns),
            'text_columns': text_columns,
            'numeric_columns': numeric_columns,
            'date_columns': date_columns,
            'estimated_bytes_per_row': int(total_bytes_per_row),
            'estimated_total_bytes': int(estimated_size_bytes),
            'estimated_mb': round(estimated_size_bytes / (1024 * 1024), 2),
            'sample_rows': sample_rows
        }

    def estimate_scan_time(self, total_rows: int, columns: int, text_columns: int,
                           estimated_mb: float, sample_rows: int) -> Dict:
        """ìŠ¤ìº” ì‹œê°„ ì˜ˆì¸¡ (Oracle + Polars ê¸°ì¤€)"""
        base_speed_rows_per_sec = 45000  # Oracleì€ MySQLë³´ë‹¤ ì•½ê°„ ëŠë¦¼
        regex_speed_factor = 0.3
        text_factor = 1 + (text_columns * 0.1)

        effective_speed = base_speed_rows_per_sec * regex_speed_factor / text_factor

        # Oracle ì¿¼ë¦¬ëŠ” MySQLë³´ë‹¤ ì•½ê°„ ëŠë¦¼
        db_query_time = max(0.2, total_rows / 800000)
        dataframe_creation_time = max(0.05, estimated_mb / 80)
        pattern_scan_time = sample_rows / effective_speed

        total_estimated_seconds = db_query_time + dataframe_creation_time + pattern_scan_time

        return {
            'engine': 'Oracle + Polars',
            'db_query_time_sec': round(db_query_time, 2),
            'dataframe_creation_time_sec': round(dataframe_creation_time, 2),
            'pattern_scan_time_sec': round(pattern_scan_time, 2),
            'total_estimated_sec': round(total_estimated_seconds, 2),
            'estimated_rows_per_sec': int(effective_speed),
            'text_columns_factor': round(text_factor, 2)
        }

    def load_table_sample(self, schema: str, table: str) -> Tuple[Optional[pl.DataFrame], Dict]:
        """í…Œì´ë¸”ì—ì„œ ìƒ˜í”Œ ë°ì´í„°ë¥¼ Polars DataFrameìœ¼ë¡œ ë¡œë“œ"""
        cursor = self.connection.cursor()

        table_info = self.get_table_info(schema, table)
        total_rows = table_info['total_rows']

        if total_rows == 0:
            print(f"    âš ï¸  ë¹ˆ í…Œì´ë¸”")
            return None, {'method': 'empty', 'total_rows': 0, 'sampled_rows': 0}

        # Oracle ìƒ˜í”Œë§ ì¿¼ë¦¬
        if total_rows <= self.sample_size:
            query = f"SELECT * FROM {schema}.{table}"
            sample_method = "ì „ì²´ ë°ì´í„°"
        else:
            # Oracleì˜ SAMPLE ì‚¬ìš© (ë” íš¨ìœ¨ì )
            sample_percent = min(50, (self.sample_size / total_rows) * 100 * 2)  # ì•½ê°„ ì—¬ìœ ìˆê²Œ
            query = f"""
                SELECT * FROM (
                    SELECT * FROM {schema}.{table} SAMPLE({sample_percent:.2f})
                    ORDER BY DBMS_RANDOM.VALUE
                ) WHERE ROWNUM <= {self.sample_size}
            """
            sample_method = f"Oracle SAMPLE ({sample_percent:.1f}%)"

        try:
            cursor.execute(query)
            rows = cursor.fetchall()

            if not rows:
                return None, {'method': 'no_data', 'total_rows': total_rows, 'sampled_rows': 0}

            # ì»¬ëŸ¼ëª… ì¶”ì¶œ
            columns = [desc[0] for desc in cursor.description]

            # Oracleì˜ Noneì„ ì²˜ë¦¬í•˜ì—¬ Polars DataFrame ìƒì„±
            processed_rows = []
            for row in rows:
                processed_row = []
                for value in row:
                    if value is None:
                        processed_row.append(None)
                    elif isinstance(value, cx_Oracle.LOB):
                        # CLOB/BLOB ì²˜ë¦¬
                        try:
                            processed_row.append(value.read())
                        except:
                            processed_row.append(str(value))
                    else:
                        processed_row.append(value)
                processed_rows.append(processed_row)

            df = pl.DataFrame(processed_rows, schema=columns)

            sampling_info = {
                'method': sample_method,
                'total_rows': total_rows,
                'sampled_rows': len(processed_rows),
                'sampling_ratio': len(processed_rows) / total_rows if total_rows > 0 else 0
            }

            print(f"    ğŸ“Š {total_rows:,}í–‰ â†’ {len(processed_rows)}í–‰ ìƒ˜í”Œë§ ({sample_method})")

            return df, sampling_info

        except Exception as e:
            print(f"    âŒ ë°ì´í„° ë¡œë“œ ì˜¤ë¥˜: {str(e)}")
            return None, {'method': 'error', 'error': str(e)}
        finally:
            cursor.close()

    def is_privacy_column(self, column_name: str) -> bool:
        """ì»¬ëŸ¼ëª…ì´ ê°œì¸ì •ë³´ ê´€ë ¨ ì»¬ëŸ¼ì¸ì§€ í™•ì¸"""
        column_lower = column_name.lower()
        return any(keyword in column_lower for keyword in self.privacy_keywords)

    def scan_column_patterns(self, df: pl.DataFrame, column: str) -> Dict:
        """Polars DataFrame ì»¬ëŸ¼ì—ì„œ ê°œì¸ì •ë³´ íŒ¨í„´ ìŠ¤ìº”"""
        if df is None:
            return {'error': 'DataFrame is None'}

        try:
            if column not in df.columns:
                return {'error': f'Column {column} not found'}

            # nullì´ ì•„ë‹Œ ë°ì´í„°ë§Œ ì¶”ì¶œí•˜ê³  ë¬¸ìì—´ë¡œ ë³€í™˜
            col_data = df.select(pl.col(column).filter(pl.col(column).is_not_null())).to_series()
            values = [str(val) for val in col_data.to_list() if val is not None]

            if not values:
                return {'privacy_matches': {}, 'total_values': 0, 'privacy_count': 0, 'privacy_ratio': 0}

            privacy_matches = {}
            privacy_rows = set()

            for idx, value in enumerate(values):
                for pattern_name, pattern in self.privacy_patterns.items():
                    matches = re.findall(pattern, value)
                    if matches:
                        if pattern_name not in privacy_matches:
                            privacy_matches[pattern_name] = 0
                        privacy_matches[pattern_name] += len(matches)
                        privacy_rows.add(idx)

            total_values = len(values)
            privacy_count = len(privacy_rows)
            privacy_ratio = privacy_count / total_values if total_values > 0 else 0

            return {
                'privacy_matches': privacy_matches,
                'total_values': total_values,
                'privacy_count': privacy_count,
                'privacy_ratio': privacy_ratio,
                'sample_values': self.mask_sample_data(values[:5])
            }

        except Exception as e:
            return {'error': str(e)}

    def mask_sample_data(self, values: List[str]) -> List[str]:
        """ìƒ˜í”Œ ë°ì´í„° ë§ˆìŠ¤í‚¹"""
        masked = []
        for value in values:
            value = re.sub(r'([a-zA-Z0-9._%+-]+)@([a-zA-Z0-9.-]+\.[a-zA-Z]{2,})',
                           lambda m: f"{m.group(1)[:2]}***@{m.group(2)}", value)
            value = re.sub(r'(\d{2,3})-(\d{3,4})-(\d{4})', r'\1-***-\3', value)
            value = re.sub(r'(\d{6})-([1-4])(\d{6})', r'\1-\2******', value)
            value = re.sub(r'(\d{4})-(\d{4})-(\d{4})-(\d{4})', r'\1-****-****-\4', value)

            masked.append(value[:50] + "..." if len(value) > 50 else value)

        return masked

    def analyze_dataframe(self, df: pl.DataFrame, schema: str, table_name: str, sampling_info: Dict) -> Dict:
        """Polars DataFrame ì „ì²´ ë¶„ì„"""
        if df is None:
            return {
                'schema': schema,
                'table': table_name,
                'sampling_info': sampling_info,
                'columns': {},
                'privacy_score': 0,
                'risk_level': 'EMPTY' if sampling_info.get('total_rows', 0) == 0 else 'ERROR'
            }

        print(f"    ğŸ” DataFrame ë¶„ì„ ì¤‘... (Polars)")

        result = {
            'schema': schema,
            'table': table_name,
            'sampling_info': sampling_info,
            'columns': {},
            'privacy_score': 0,
            'risk_level': 'LOW'
        }

        for column in df.columns:
            column_name = str(column)
            col_type = str(df[column].dtype)
            is_suspicious = self.is_privacy_column(column_name)

            column_result = {
                'type': col_type,
                'suspicious_name': is_suspicious,
                'pattern_scan': None
            }

            if any(t in col_type.lower() for t in ['string', 'utf8', 'str']):
                pattern_result = self.scan_column_patterns(df, column_name)
                column_result['pattern_scan'] = pattern_result

                if 'privacy_matches' in pattern_result and pattern_result['privacy_matches']:
                    pattern_score = len(pattern_result['privacy_matches']) * 3
                    ratio_score = int(pattern_result.get('privacy_ratio', 0) * 10)
                    column_score = pattern_score + ratio_score
                    result['privacy_score'] += column_score

                    print(f"      ğŸš¨ {column_name}: {list(pattern_result['privacy_matches'].keys())} "
                          f"(ë¹„ìœ¨: {pattern_result.get('privacy_ratio', 0):.1%})")

                elif is_suspicious:
                    result['privacy_score'] += 1
                    print(f"      âš ï¸  {column_name}: ì˜ì‹¬ìŠ¤ëŸ¬ìš´ ì»¬ëŸ¼ëª…")

            result['columns'][column_name] = column_result

        if result['privacy_score'] >= 15:
            result['risk_level'] = 'HIGH'
        elif result['privacy_score'] >= 5:
            result['risk_level'] = 'MEDIUM'

        return result

    def scan_table(self, schema: str, table: str) -> Dict:
        """í…Œì´ë¸” ìŠ¤ìº” (Oracle + Polars ê¸°ë°˜)"""
        print(f"  ğŸ“‹ í…Œì´ë¸” ìŠ¤ìº”: {schema}.{table}")

        df, sampling_info = self.load_table_sample(schema, table)
        result = self.analyze_dataframe(df, schema, table, sampling_info)

        print(f"    âœ… ì™„ë£Œ (ìœ„í—˜ë„: {result['risk_level']}, ì ìˆ˜: {result['privacy_score']})")

        return result

    def analyze_schema_structure(self, schema: str) -> Dict:
        """ìŠ¤í‚¤ë§ˆ êµ¬ì¡° ë¶„ì„ ë° ì²˜ë¦¬ ë¹„ìš© ì˜ˆì¸¡"""
        print(f"ğŸ” ìŠ¤í‚¤ë§ˆ êµ¬ì¡° ë¶„ì„ ì¤‘: {schema}")

        analysis = {
            'schema': schema,
            'analysis_time': datetime.now().isoformat(),
            'engine': 'Oracle + Polars',
            'sample_size': self.sample_size,
            'tables': {},
            'summary': {
                'total_tables': 0,
                'total_rows': 0,
                'total_columns': 0,
                'total_text_columns': 0,
                'estimated_total_mb': 0,
                'estimated_total_scan_time_sec': 0,
                'scannable_tables': 0,
                'empty_tables': 0,
                'large_tables': 0
            }
        }

        try:
            tables = self.get_tables(schema)
            analysis['summary']['total_tables'] = len(tables)

            print(f"  ğŸ“Š ë°œê²¬ëœ í…Œì´ë¸”: {len(tables)}ê°œ")

            for table in tables:
                print(f"    ğŸ“‹ ë¶„ì„ ì¤‘: {table}")

                try:
                    table_info = self.get_table_info(schema, table)
                    total_rows = table_info['total_rows']
                    columns = table_info['columns']

                    sample_rows = min(total_rows, self.sample_size) if total_rows > 0 else 0
                    size_estimate = self.estimate_dataframe_size(columns, sample_rows)
                    time_estimate = self.estimate_scan_time(
                        total_rows,
                        len(columns),
                        size_estimate['text_columns'],
                        size_estimate['estimated_mb'],
                        sample_rows
                    )

                    table_analysis = {
                        'total_rows': total_rows,
                        'total_columns': len(columns),
                        'columns': columns,
                        'size_estimate': size_estimate,
                        'time_estimate': time_estimate,
                        'status': 'scannable' if total_rows > 0 else 'empty'
                    }

                    analysis['tables'][table] = table_analysis

                    analysis['summary']['total_rows'] += total_rows
                    analysis['summary']['total_columns'] += len(columns)
                    analysis['summary']['total_text_columns'] += size_estimate['text_columns']
                    analysis['summary']['estimated_total_mb'] += size_estimate['estimated_mb']
                    analysis['summary']['estimated_total_scan_time_sec'] += time_estimate['total_estimated_sec']

                    if total_rows == 0:
                        analysis['summary']['empty_tables'] += 1
                    else:
                        analysis['summary']['scannable_tables'] += 1

                    if total_rows >= 1000000:
                        analysis['summary']['large_tables'] += 1

                    print(f"      âœ… {total_rows:,}í–‰, {len(columns)}ì»¬ëŸ¼, "
                          f"~{size_estimate['estimated_mb']}MB, "
                          f"~{time_estimate['total_estimated_sec']}ì´ˆ")

                except Exception as e:
                    analysis['tables'][table] = {
                        'error': str(e),
                        'status': 'error'
                    }
                    print(f"      âŒ ë¶„ì„ ì˜¤ë¥˜: {str(e)}")

        except Exception as e:
            analysis['error'] = str(e)
            print(f"âŒ ìŠ¤í‚¤ë§ˆ ë¶„ì„ ì˜¤ë¥˜: {str(e)}")

        return analysis

    def scan_schema(self, schema: str) -> Dict:
        """ìŠ¤í‚¤ë§ˆ ì „ì²´ ìŠ¤ìº”"""
        print(f"ğŸ” ìŠ¤í‚¤ë§ˆ ìŠ¤ìº” ì‹œì‘: {schema} (Oracle + Polars ì—”ì§„)")

        scan_results = {
            'schema': schema,
            'scan_time': datetime.now().isoformat(),
            'engine': 'Oracle + Polars',
            'sample_size': self.sample_size,
            'tables': {},
            'summary': {
                'total_tables': 0,
                'scanned_tables': 0,
                'high_risk_tables': 0,
                'medium_risk_tables': 0,
                'low_risk_tables': 0,
                'total_privacy_score': 0,
                'total_data_rows': 0,
                'total_sampled_rows': 0
            }
        }

        try:
            tables = self.get_tables(schema)
            scan_results['summary']['total_tables'] = len(tables)

            for table in tables:
                table_result = self.scan_table(schema, table)
                scan_results['tables'][table] = table_result

                risk_level = table_result.get('risk_level', 'LOW')
                privacy_score = table_result.get('privacy_score', 0)
                sampling_info = table_result.get('sampling_info', {})

                if risk_level == 'HIGH':
                    scan_results['summary']['high_risk_tables'] += 1
                elif risk_level == 'MEDIUM':
                    scan_results['summary']['medium_risk_tables'] += 1
                elif risk_level == 'LOW':
                    scan_results['summary']['low_risk_tables'] += 1

                scan_results['summary']['scanned_tables'] += 1
                scan_results['summary']['total_privacy_score'] += privacy_score
                scan_results['summary']['total_data_rows'] += sampling_info.get('total_rows', 0)
                scan_results['summary']['total_sampled_rows'] += sampling_info.get('sampled_rows', 0)

        except Exception as e:
            scan_results['error'] = str(e)
            print(f"âŒ ìŠ¤í‚¤ë§ˆ ìŠ¤ìº” ì˜¤ë¥˜: {str(e)}")

        return scan_results

    def generate_structure_report(self, analysis: Dict) -> str:
        """ìŠ¤í‚¤ë§ˆ êµ¬ì¡° ë¶„ì„ ë¦¬í¬íŠ¸ ìƒì„±"""
        report = []
        report.append("=" * 80)
        report.append("ğŸ”® Oracle ìŠ¤í‚¤ë§ˆ êµ¬ì¡° ë¶„ì„ ë° ì²˜ë¦¬ ë¹„ìš© ì˜ˆì¸¡")
        report.append("=" * 80)
        report.append(f"ìŠ¤í‚¤ë§ˆ: {analysis['schema']}")
        report.append(f"ë¶„ì„ ì‹œê°„: {analysis['analysis_time']}")
        report.append(f"ì²˜ë¦¬ ì—”ì§„: Oracle + Polars")
        report.append(f"ìƒ˜í”Œ í¬ê¸°: {analysis.get('sample_size', 'Unknown')}ê±´")
        report.append("")

        summary = analysis.get('summary', {})

        report.append("ğŸ“Š ì „ì²´ ìš”ì•½:")
        report.append(f"  â€¢ ì´ í…Œì´ë¸” ìˆ˜: {summary.get('total_tables', 0):,}ê°œ")
        report.append(f"  â€¢ ìŠ¤ìº” ê°€ëŠ¥í•œ í…Œì´ë¸”: {summary.get('scannable_tables', 0):,}ê°œ")
        report.append(f"  â€¢ ë¹ˆ í…Œì´ë¸”: {summary.get('empty_tables', 0):,}ê°œ")
        report.append(f"  â€¢ ëŒ€ìš©ëŸ‰ í…Œì´ë¸” (100ë§Œí–‰+): {summary.get('large_tables', 0):,}ê°œ")
        report.append(f"  â€¢ ì´ ë°ì´í„° í–‰ ìˆ˜: {summary.get('total_rows', 0):,}í–‰")
        report.append(f"  â€¢ ì´ ì»¬ëŸ¼ ìˆ˜: {summary.get('total_columns', 0):,}ê°œ")
        report.append(f"  â€¢ í…ìŠ¤íŠ¸ ì»¬ëŸ¼ ìˆ˜: {summary.get('total_text_columns', 0):,}ê°œ")
        report.append("")

        estimated_mb = summary.get('estimated_total_mb', 0)
        estimated_time = summary.get('estimated_total_scan_time_sec', 0)

        report.append("ğŸ’¾ ì˜ˆìƒ ì²˜ë¦¬ ë¹„ìš© (Oracle + Polars ì—”ì§„):")
        report.append(f"  â€¢ ì˜ˆìƒ DataFrame í¬ê¸°: {estimated_mb:.1f} MB")
        if estimated_mb < 10:
            report.append(f"    â†’ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: ğŸŸ¢ ë‚®ìŒ")
        elif estimated_mb < 100:
            report.append(f"    â†’ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: ğŸŸ¡ ë³´í†µ")
        else:
            report.append(f"    â†’ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: ğŸ”´ ë†’ìŒ")

        report.append(f"  â€¢ ì˜ˆìƒ ìŠ¤ìº” ì‹œê°„: {estimated_time:.1f}ì´ˆ")
        if estimated_time < 30:
            report.append(f"    â†’ ì²˜ë¦¬ ì‹œê°„: ğŸŸ¢ ë¹ ë¦„")
        elif estimated_time < 300:
            report.append(f"    â†’ ì²˜ë¦¬ ì‹œê°„: ğŸŸ¡ ë³´í†µ")
        else:
            report.append(f"    â†’ ì²˜ë¦¬ ì‹œê°„: ğŸ”´ ì˜¤ë˜ ê±¸ë¦¼")

        if estimated_time > 60:
            minutes = int(estimated_time // 60)
            seconds = int(estimated_time % 60)
            report.append(f"    â†’ ì˜ˆìƒ ì‹œê°„: {minutes}ë¶„ {seconds}ì´ˆ")

        report.append("")
        report.append("ğŸ’¡ Oracle íŠ¹í™” ê¶Œì¥ì‚¬í•­:")
        report.append("  â€¢ Oracle SAMPLEì„ ì´ìš©í•œ íš¨ìœ¨ì ì¸ ìƒ˜í”Œë§")
        report.append("  â€¢ CLOB/BLOB ì»¬ëŸ¼ ìë™ ì²˜ë¦¬")
        report.append("  â€¢ ìŠ¤í‚¤ë§ˆë³„ ë…ë¦½ì ì¸ ìŠ¤ìº” ê°€ëŠ¥")

        return "\n".join(report)

    def generate_scan_report(self, scan_results: Dict) -> str:
        """ìŠ¤ìº” ê²°ê³¼ ë¦¬í¬íŠ¸ ìƒì„±"""
        report = []
        report.append("=" * 80)
        report.append("ğŸ“Š Oracle ê°œì¸ì •ë³´ ìŠ¤ìº” ë¦¬í¬íŠ¸")
        report.append("=" * 80)
        report.append(f"ìŠ¤í‚¤ë§ˆ: {scan_results['schema']}")
        report.append(f"ìŠ¤ìº” ì‹œê°„: {scan_results['scan_time']}")
        report.append(f"ì²˜ë¦¬ ì—”ì§„: Oracle + Polars")
        report.append(f"ìƒ˜í”Œ ì‚¬ì´ì¦ˆ: {scan_results.get('sample_size', 'Unknown')}ê±´")
        report.append("")

        summary = scan_results.get('summary', {})
        total_data_rows = summary.get('total_data_rows', 0)
        total_sampled_rows = summary.get('total_sampled_rows', 0)

        report.append("ğŸ“‹ ìŠ¤ìº” ìš”ì•½:")
        report.append(f"  â€¢ ì´ í…Œì´ë¸” ìˆ˜: {summary.get('total_tables', 0)}")
        report.append(f"  â€¢ ìŠ¤ìº”ëœ í…Œì´ë¸” ìˆ˜: {summary.get('scanned_tables', 0)}")
        report.append(f"  â€¢ ê³ ìœ„í—˜ í…Œì´ë¸”: {summary.get('high_risk_tables', 0)}ê°œ")
        report.append(f"  â€¢ ì¤‘ê°„ìœ„í—˜ í…Œì´ë¸”: {summary.get('medium_risk_tables', 0)}ê°œ")
        report.append(f"  â€¢ ì €ìœ„í—˜ í…Œì´ë¸”: {summary.get('low_risk_tables', 0)}ê°œ")
        report.append(f"  â€¢ ì´ ê°œì¸ì •ë³´ ìœ„í—˜ë„ ì ìˆ˜: {summary.get('total_privacy_score', 0)}")
        report.append(f"  â€¢ ì „ì²´ ë°ì´í„° í–‰ ìˆ˜: {total_data_rows:,}")
        report.append(f"  â€¢ ìƒ˜í”Œë§ëœ í–‰ ìˆ˜: {total_sampled_rows:,}")

        if total_data_rows > 0:
            sampling_efficiency = total_sampled_rows / total_data_rows
            report.append(f"  â€¢ ìƒ˜í”Œë§ íš¨ìœ¨: {sampling_efficiency:.1%}")

        report.append("")

        # ê³ ìœ„í—˜ í…Œì´ë¸” ìƒì„¸ ì •ë³´
        high_risk_tables = []
        for table_name, table_data in scan_results.get('tables', {}).items():
            if table_data.get('risk_level') == 'HIGH':
                high_risk_tables.append({
                    'name': table_name,
                    'score': table_data.get('privacy_score', 0),
                    'data': table_data
                })

        high_risk_tables.sort(key=lambda x: x['score'], reverse=True)

        if high_risk_tables:
            report.append("ğŸš¨ ê³ ìœ„í—˜ í…Œì´ë¸” ìƒì„¸:")
            for table_info in high_risk_tables:
                table_name = table_info['name']
                table_data = table_info['data']
                sampling_info = table_data.get('sampling_info', {})
                schema = table_data.get('schema', 'Unknown')

                report.append(f"  â€¢ {schema}.{table_name} (ì ìˆ˜: {table_info['score']})")
                report.append(f"    - ì´ í–‰ìˆ˜: {sampling_info.get('total_rows', 0):,}")
                report.append(f"    - ìƒ˜í”Œë§: {sampling_info.get('method', 'Unknown')}")

                privacy_columns = []
                for col_name, col_data in table_data.get('columns', {}).items():
                    pattern_scan = col_data.get('pattern_scan', {})
                    if pattern_scan and 'privacy_matches' in pattern_scan and pattern_scan['privacy_matches']:
                        matches = pattern_scan['privacy_matches']
                        ratio = pattern_scan.get('privacy_ratio', 0)
                        match_details = [f"{k}({v})" for k, v in matches.items()]
                        privacy_columns.append(f"      - {col_name}: {', '.join(match_details)} [ë¹„ìœ¨: {ratio:.1%}]")
                    elif col_data.get('suspicious_name'):
                        privacy_columns.append(f"      - {col_name}: ì˜ì‹¬ìŠ¤ëŸ¬ìš´ ì»¬ëŸ¼ëª…")

                if privacy_columns:
                    report.extend(privacy_columns)
                report.append("")

        # Oracle íŠ¹í™” ì„±ëŠ¥ ì •ë³´
        report.append("âš¡ Oracle íŠ¹í™” ì„±ëŠ¥ ì •ë³´:")
        report.append("  â€¢ Oracle SAMPLE ê¸°ë°˜ ê³ ì† ìƒ˜í”Œë§")
        report.append("  â€¢ CLOB/BLOB ë°ì´í„° ìë™ ì²˜ë¦¬")
        report.append("  â€¢ Polars ë²¡í„°í™” ë¶„ì„ ì—”ì§„")
        report.append("  â€¢ ìŠ¤í‚¤ë§ˆë³„ ë…ë¦½ì  ì²˜ë¦¬")

        return "\n".join(report)

    def preview_all_schemas(self) -> List[Dict]:
        """ëª¨ë“  ìŠ¤í‚¤ë§ˆ êµ¬ì¡° ë¶„ì„ ë° ì²˜ë¦¬ ë¹„ìš© ì˜ˆì¸¡"""
        if not self.connect():
            return []

        try:
            schemas = self.get_schemas()

            print(f"ğŸ¯ ë°œê²¬ëœ ì‚¬ìš©ì ìŠ¤í‚¤ë§ˆ: {len(schemas)}ê°œ")
            print(f"âš¡ ë¶„ì„ ì—”ì§„: Oracle + Polars")
            print(f"ğŸ“Š ìƒ˜í”Œë§ ì„¤ì •: í…Œì´ë¸”ë‹¹ ìµœëŒ€ {self.sample_size}ê±´")
            print("=" * 60)

            all_analyses = []
            total_start_time = datetime.now()

            for i, schema in enumerate(schemas, 1):
                print(f"\n[{i}/{len(schemas)}] ìŠ¤í‚¤ë§ˆ êµ¬ì¡° ë¶„ì„ ì¤‘...")

                analysis_start_time = datetime.now()
                analysis = self.analyze_schema_structure(schema)
                analysis_end_time = datetime.now()

                analysis['analysis_duration'] = str(analysis_end_time - analysis_start_time)
                all_analyses.append(analysis)

                print(self.generate_structure_report(analysis))
                print(f"â±ï¸  ë¶„ì„ ì‹œê°„: {analysis_end_time - analysis_start_time}")
                print("\n" + "=" * 80 + "\n")

            total_end_time = datetime.now()
            self.generate_total_preview_summary(all_analyses, total_end_time - total_start_time)

            return all_analyses

        finally:
            self.disconnect()

    def generate_total_preview_summary(self, all_analyses: List[Dict], total_time) -> None:
        """ì „ì²´ ìŠ¤í‚¤ë§ˆ ì˜ˆì¸¡ ìš”ì•½"""
        print("ğŸ¯ ì „ì²´ Oracle ìŠ¤í‚¤ë§ˆ ì²˜ë¦¬ ë¹„ìš© ì˜ˆì¸¡ ìš”ì•½")
        print("=" * 60)

        total_tables = sum(a.get('summary', {}).get('total_tables', 0) for a in all_analyses)
        total_rows = sum(a.get('summary', {}).get('total_rows', 0) for a in all_analyses)
        total_columns = sum(a.get('summary', {}).get('total_columns', 0) for a in all_analyses)
        total_mb = sum(a.get('summary', {}).get('estimated_total_mb', 0) for a in all_analyses)
        total_scan_time = sum(a.get('summary', {}).get('estimated_total_scan_time_sec', 0) for a in all_analyses)
        scannable_tables = sum(a.get('summary', {}).get('scannable_tables', 0) for a in all_analyses)
        large_tables = sum(a.get('summary', {}).get('large_tables', 0) for a in all_analyses)

        print(f"ğŸ“Š ì „ì²´ ê·œëª¨:")
        print(f"  â€¢ ìŠ¤í‚¤ë§ˆ ìˆ˜: {len(all_analyses)}ê°œ")
        print(f"  â€¢ ì´ í…Œì´ë¸” ìˆ˜: {total_tables:,}ê°œ")
        print(f"  â€¢ ìŠ¤ìº” ê°€ëŠ¥í•œ í…Œì´ë¸”: {scannable_tables:,}ê°œ")
        print(f"  â€¢ ëŒ€ìš©ëŸ‰ í…Œì´ë¸” (100ë§Œí–‰+): {large_tables:,}ê°œ")
        print(f"  â€¢ ì´ ë°ì´í„° í–‰ ìˆ˜: {total_rows:,}í–‰")
        print(f"  â€¢ ì´ ì»¬ëŸ¼ ìˆ˜: {total_columns:,}ê°œ")

        print(f"\nğŸ’¾ ì˜ˆìƒ ì²˜ë¦¬ ë¹„ìš© (Oracle + Polars ì—”ì§„):")
        print(f"  â€¢ ì˜ˆìƒ ì´ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: {total_mb:.1f} MB")
        print(f"  â€¢ ì˜ˆìƒ ì´ ìŠ¤ìº” ì‹œê°„: {total_scan_time:.1f}ì´ˆ")

        if total_scan_time > 60:
            minutes = int(total_scan_time // 60)
            seconds = int(total_scan_time % 60)
            print(f"    â†’ {minutes}ë¶„ {seconds}ì´ˆ")

        print(f"\nğŸš¦ ì²˜ë¦¬ ìœ„í—˜ë„ í‰ê°€:")

        memory_risk = "ğŸŸ¢ ë‚®ìŒ" if total_mb < 100 else "ğŸŸ¡ ë³´í†µ" if total_mb < 500 else "ğŸ”´ ë†’ìŒ"
        time_risk = "ğŸŸ¢ ë¹ ë¦„" if total_scan_time < 60 else "ğŸŸ¡ ë³´í†µ" if total_scan_time < 600 else "ğŸ”´ ì˜¤ë˜ ê±¸ë¦¼"

        print(f"  â€¢ ë©”ëª¨ë¦¬ ìœ„í—˜ë„: {memory_risk} ({total_mb:.1f} MB)")
        print(f"  â€¢ ì‹œê°„ ìœ„í—˜ë„: {time_risk} ({total_scan_time:.1f}ì´ˆ)")

        if large_tables > 20:
            print(f"  â€¢ ëŒ€ìš©ëŸ‰ í…Œì´ë¸” ìœ„í—˜ë„: ğŸ”´ ë†’ìŒ ({large_tables}ê°œ)")
        elif large_tables > 5:
            print(f"  â€¢ ëŒ€ìš©ëŸ‰ í…Œì´ë¸” ìœ„í—˜ë„: ğŸŸ¡ ë³´í†µ ({large_tables}ê°œ)")
        else:
            print(f"  â€¢ ëŒ€ìš©ëŸ‰ í…Œì´ë¸” ìœ„í—˜ë„: ğŸŸ¢ ë‚®ìŒ ({large_tables}ê°œ)")

        print(f"\nâ±ï¸  ì „ì²´ ë¶„ì„ ì‹œê°„: {total_time}")
        print(f"ğŸ”® Oracle + Polars ì—”ì§„ìœ¼ë¡œ ìµœì í™”ëœ ì²˜ë¦¬ ì¤€ë¹„ ì™„ë£Œ!")

        print(f"\nğŸ’¡ Oracle íŠ¹í™” ê¶Œì¥ì‚¬í•­:")
        print(f"  â€¢ SAMPLEì„ ì´ìš©í•œ íš¨ìœ¨ì ì¸ ëŒ€ìš©ëŸ‰ í…Œì´ë¸” ì²˜ë¦¬")
        print(f"  â€¢ CLOB/BLOB ì»¬ëŸ¼ ìë™ ë³€í™˜ ì²˜ë¦¬")
        print(f"  â€¢ ìŠ¤í‚¤ë§ˆë³„ ìˆœì°¨ ì²˜ë¦¬ë¡œ ë©”ëª¨ë¦¬ íš¨ìœ¨ì„± í™•ë³´")
        print(f"  â€¢ Oracle ì‹œìŠ¤í…œ ìŠ¤í‚¤ë§ˆ ìë™ ì œì™¸")

        print(f"\nâœ… êµ¬ì¡° ë¶„ì„ ì™„ë£Œ! ì´ì œ ì‹¤ì œ ìŠ¤ìº”ì„ ì‹¤í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        print("=" * 60)

    def scan_all_schemas(self) -> List[Dict]:
        """ëª¨ë“  ìŠ¤í‚¤ë§ˆ ìŠ¤ìº” (ì‹¤ì œ ê°œì¸ì •ë³´ íƒì§€)"""
        if not self.connect():
            return []

        try:
            schemas = self.get_schemas()

            print(f"ğŸ¯ ë°œê²¬ëœ ì‚¬ìš©ì ìŠ¤í‚¤ë§ˆ: {len(schemas)}ê°œ")
            print(f"âš¡ ì²˜ë¦¬ ì—”ì§„: Oracle + Polars")
            print(f"ğŸ“Š ìƒ˜í”Œë§: í…Œì´ë¸”ë‹¹ ìµœëŒ€ {self.sample_size}ê±´")
            print("=" * 60)

            all_results = []
            total_start_time = datetime.now()

            for i, schema in enumerate(schemas, 1):
                print(f"\n[{i}/{len(schemas)}] ìŠ¤í‚¤ë§ˆ ì²˜ë¦¬ ì¤‘...")

                schema_start_time = datetime.now()
                result = self.scan_schema(schema)
                schema_end_time = datetime.now()

                result['processing_time'] = str(schema_end_time - schema_start_time)
                all_results.append(result)

                print(self.generate_scan_report(result))
                print(f"â±ï¸  ì²˜ë¦¬ ì‹œê°„: {schema_end_time - schema_start_time}")
                print("\n" + "=" * 80 + "\n")

            total_end_time = datetime.now()
            print(f"ğŸ‰ ì „ì²´ ìŠ¤ìº” ì™„ë£Œ! (Oracle + Polars ì—”ì§„)")
            print(f"â±ï¸  ì´ ì²˜ë¦¬ ì‹œê°„: {total_end_time - total_start_time}")

            return all_results

        finally:
            self.disconnect()


# ì‚¬ìš© ì˜ˆì‹œ
if __name__ == "__main__":
    # Oracle ê¸°ë°˜ ìŠ¤ìºë„ˆ ì´ˆê¸°í™”
    scanner = OraclePrivacyScanner(
        host="localhost",
        port=1521,
        service_name="ORCL",  # ë˜ëŠ” "XE", "XEPDB1" ë“±
        user="your_username",
        password="your_password",
        sample_size=100
    )

    print("ğŸ”® Oracle ê¸°ë°˜ ê°œì¸ì •ë³´ ìŠ¤ìºë„ˆ")
    print("ğŸ“¦ í™˜ê²½ ì„¤ì •:")
    print("   uv venv oracle-privacy-scanner")
    print("   source oracle-privacy-scanner/bin/activate  # Linux/Mac")
    print("   # oracle-privacy-scanner\\Scripts\\activate  # Windows")
    print("   uv add polars cx-Oracle")
    print("=" * 60)
    print("ìë™ ì‹¤í–‰ ìˆœì„œ: êµ¬ì¡° ë¶„ì„ â†’ ë¹„ìš© ì˜ˆì¸¡ â†’ ê°œì¸ì •ë³´ ìŠ¤ìº”")
    print("=" * 60)

    try:
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')

        # 1ë‹¨ê³„: ìŠ¤í‚¤ë§ˆ êµ¬ì¡° ë¶„ì„
        print("\nğŸ” 1ë‹¨ê³„: Oracle ìŠ¤í‚¤ë§ˆ êµ¬ì¡° ë¶„ì„ ì‹œì‘...")
        analyses = scanner.preview_all_schemas()

        analysis_filename = f"oracle_schema_analysis_{timestamp}.json"
        with open(analysis_filename, "w", encoding="utf-8") as f:
            json.dump(analyses, f, ensure_ascii=False, indent=2)

        print(f"\nğŸ’¾ êµ¬ì¡° ë¶„ì„ ê²°ê³¼ê°€ {analysis_filename}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

        # 2ë‹¨ê³„: ì‚¬ìš©ì í™•ì¸ (ìë™ ì§„í–‰)
        print("\nâ³ 3ì´ˆ í›„ ê°œì¸ì •ë³´ ìŠ¤ìº”ì„ ìë™ìœ¼ë¡œ ì‹œì‘í•©ë‹ˆë‹¤...")
        import time

        time.sleep(3)

        # 3ë‹¨ê³„: ê°œì¸ì •ë³´ ìŠ¤ìº” ì‹¤í–‰
        print("\nğŸš€ 2ë‹¨ê³„: Oracle ê°œì¸ì •ë³´ ìŠ¤ìº” ì‹¤í–‰...")
        results = scanner.scan_all_schemas()

        scan_filename = f"oracle_privacy_scan_{timestamp}.json"
        with open(scan_filename, "w", encoding="utf-8") as f:
            json.dump(results, f, ensure_ascii=False, indent=2)

        print(f"\nâœ… ì „ì²´ í”„ë¡œì„¸ìŠ¤ ì™„ë£Œ!")
        print(f"ğŸ“„ êµ¬ì¡° ë¶„ì„: {analysis_filename}")
        print(f"ğŸ“„ ìŠ¤ìº” ê²°ê³¼: {scan_filename}")

        # ì „ì²´ ìš”ì•½
        if results:
            total_tables = sum(r.get('summary', {}).get('total_tables', 0) for r in results)
            total_high_risk = sum(r.get('summary', {}).get('high_risk_tables', 0) for r in results)
            total_score = sum(r.get('summary', {}).get('total_privacy_score', 0) for r in results)
            total_data_rows = sum(r.get('summary', {}).get('total_data_rows', 0) for r in results)

            print(f"\nğŸ“Š ìµœì¢… ì „ì²´ ìš”ì•½:")
            print(f"  â€¢ ì²˜ë¦¬ ì—”ì§„: Oracle + Polars")
            print(f"  â€¢ ìŠ¤ìº”ëœ ìŠ¤í‚¤ë§ˆ: {len(results)}ê°œ")
            print(f"  â€¢ ì´ í…Œì´ë¸” ìˆ˜: {total_tables}")
            print(f"  â€¢ ì´ ë°ì´í„° í–‰ ìˆ˜: {total_data_rows:,}")
            print(f"  â€¢ ê³ ìœ„í—˜ í…Œì´ë¸” ìˆ˜: {total_high_risk}")
            print(f"  â€¢ ì „ì²´ ê°œì¸ì •ë³´ ìœ„í—˜ë„ ì ìˆ˜: {total_score}")
            print(f"  â€¢ Oracle + Polars ê¸°ë°˜ ê³ ì„±ëŠ¥ ì²˜ë¦¬ ì™„ë£Œ! ğŸ”®")

    except Exception as e:
        print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        print("\nğŸ’¡ í™•ì¸ì‚¬í•­:")
        print("  â€¢ Oracle ì„œë²„ê°€ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸")
        print("  â€¢ ì—°ê²° ì •ë³´ (host, port, service_name) í™•ì¸")
        print("  â€¢ ì‚¬ìš©ì ê¶Œí•œ í™•ì¸")
        print("  â€¢ cx_Oracle ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ í™•ì¸")

    print("\nğŸ‘‹ í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")