import streamlit as st
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import pandas as pd
import json
from datetime import datetime
import re
from pathlib import Path

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="ê°œì¸ì •ë³´ ìŠ¤ìº” ëŒ€ì‹œë³´ë“œ",
    page_icon="ğŸ”",
    layout="wide",
    initial_sidebar_state="expanded"
)

# CSS ìŠ¤íƒ€ì¼ë§
st.markdown("""
<style>
    .main-header {
        font-size: 2.5rem;
        font-weight: bold;
        color: #1f77b4;
        text-align: center;
        margin-bottom: 2rem;
    }
    .metric-card {
        background-color: #f0f2f6;
        padding: 1rem;
        border-radius: 0.5rem;
        border-left: 4px solid #1f77b4;
    }
    .high-risk {
        border-left-color: #ff4444 !important;
        background-color: #fff5f5;
    }
    .medium-risk {
        border-left-color: #ff8800 !important;
        background-color: #fff8f0;
    }
    .low-risk {
        border-left-color: #00cc44 !important;
        background-color: #f0fff5;
    }
</style>
""", unsafe_allow_html=True)


# ë°ì´í„° ë§ˆìŠ¤í‚¹ í•¨ìˆ˜
def mask_sensitive_data(text):
    """ë¯¼ê°í•œ ë°ì´í„° ë§ˆìŠ¤í‚¹"""
    if not isinstance(text, str):
        return text

    # ì´ë©”ì¼ ë§ˆìŠ¤í‚¹
    text = re.sub(r'([a-zA-Z0-9._%+-]+)@([a-zA-Z0-9.-]+\.[a-zA-Z]{2,})',
                  lambda m: f"{m.group(1)[:2]}***@{m.group(2)}", text)

    # ì „í™”ë²ˆí˜¸ ë§ˆìŠ¤í‚¹
    text = re.sub(r'(\d{2,3})-(\d{3,4})-(\d{4})', r'\1-***-\3', text)

    # ì£¼ë¯¼ë“±ë¡ë²ˆí˜¸ ë§ˆìŠ¤í‚¹
    text = re.sub(r'(\d{6})-([1-4])(\d{6})', r'\1-\2******', text)

    # ì¹´ë“œë²ˆí˜¸ ë§ˆìŠ¤í‚¹
    text = re.sub(r'(\d{4})-(\d{4})-(\d{4})-(\d{4})', r'\1-****-****-\4', text)

    return text


# ìœ„í—˜ë„ ìƒ‰ìƒ ë§¤í•‘
def get_risk_color(risk_level):
    colors = {
        'HIGH': '#ff4444',
        'MEDIUM': '#ff8800',
        'LOW': '#00cc44',
        'EMPTY': '#cccccc',
        'ERROR': '#ff0000'
    }
    return colors.get(risk_level, '#cccccc')


# ë©”ì¸ í—¤ë”
st.markdown('<h1 class="main-header">ğŸ” ê°œì¸ì •ë³´ ìŠ¤ìº” ëŒ€ì‹œë³´ë“œ</h1>', unsafe_allow_html=True)

# ì‚¬ì´ë“œë°”
st.sidebar.title("ğŸ“ ë°ì´í„° ë¡œë“œ")

# íŒŒì¼ ì—…ë¡œë“œ
uploaded_file = st.sidebar.file_uploader(
    "ìŠ¤ìº” ê²°ê³¼ JSON íŒŒì¼ ì—…ë¡œë“œ",
    type=['json'],
    help="Polars ê°œì¸ì •ë³´ ìŠ¤ìºë„ˆì—ì„œ ìƒì„±ëœ JSON íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”."
)

# ìƒ˜í”Œ ë°ì´í„° ë¡œë“œ ì˜µì…˜
if st.sidebar.button("ğŸ² ìƒ˜í”Œ ë°ì´í„° ì‚¬ìš©"):
    # ìƒ˜í”Œ ë°ì´í„° ìƒì„±
    sample_data = {
        "database": "sample_db",
        "scan_time": "2024-12-21T14:30:22",
        "engine": "Polars",
        "sample_size": 100,
        "summary": {
            "total_tables": 12,
            "scanned_tables": 12,
            "high_risk_tables": 3,
            "medium_risk_tables": 4,
            "low_risk_tables": 5,
            "total_privacy_score": 89,
            "total_data_rows": 1250000,
            "total_sampled_rows": 1200
        },
        "tables": {
            "users": {
                "risk_level": "HIGH",
                "privacy_score": 32,
                "sampling_info": {
                    "total_rows": 500000,
                    "sampled_rows": 100,
                    "method": "ëœë¤ ìƒ˜í”Œë§"
                },
                "columns": {
                    "name": {
                        "type": "Utf8",
                        "suspicious_name": True,
                        "pattern_scan": None
                    },
                    "email": {
                        "type": "Utf8",
                        "suspicious_name": True,
                        "pattern_scan": {
                            "privacy_matches": {"email": 98},
                            "privacy_ratio": 0.98,
                            "sample_values": ["ki***@test.com", "le***@gmail.com"]
                        }
                    },
                    "phone": {
                        "type": "Utf8",
                        "suspicious_name": True,
                        "pattern_scan": {
                            "privacy_matches": {"phone": 95},
                            "privacy_ratio": 0.95,
                            "sample_values": ["010-***-5678", "02-***-6543"]
                        }
                    }
                }
            },
            "orders": {
                "risk_level": "MEDIUM",
                "privacy_score": 15,
                "sampling_info": {
                    "total_rows": 300000,
                    "sampled_rows": 100,
                    "method": "ëœë¤ ìƒ˜í”Œë§"
                },
                "columns": {
                    "customer_email": {
                        "type": "Utf8",
                        "suspicious_name": True,
                        "pattern_scan": {
                            "privacy_matches": {"email": 89},
                            "privacy_ratio": 0.89,
                            "sample_values": ["cu***@shop.com", "bu***@store.com"]
                        }
                    }
                }
            },
            "products": {
                "risk_level": "LOW",
                "privacy_score": 0,
                "sampling_info": {
                    "total_rows": 50000,
                    "sampled_rows": 50,
                    "method": "ì „ì²´ ë°ì´í„°"
                },
                "columns": {
                    "product_name": {
                        "type": "Utf8",
                        "suspicious_name": False,
                        "pattern_scan": {
                            "privacy_matches": {},
                            "privacy_ratio": 0.0
                        }
                    }
                }
            }
        }
    }
    st.session_state.scan_data = sample_data
    st.sidebar.success("âœ… ìƒ˜í”Œ ë°ì´í„° ë¡œë“œ ì™„ë£Œ!")
    st.rerun()  # í˜ì´ì§€ ìƒˆë¡œê³ ì¹¨ìœ¼ë¡œ ë°ì´í„° ë°˜ì˜

# ë°ì´í„° ë¡œë“œ
scan_data = None
if uploaded_file is not None:
    try:
        loaded_data = json.load(uploaded_file)

        # JSONì´ ë°°ì—´ì¸ ê²½ìš° ì²« ë²ˆì§¸ ìš”ì†Œ ì‚¬ìš©
        if isinstance(loaded_data, list) and len(loaded_data) > 0:
            scan_data = loaded_data[0]
            st.sidebar.success(f"âœ… íŒŒì¼ ë¡œë“œ ì™„ë£Œ! (ë°°ì—´ì—ì„œ ì²« ë²ˆì§¸ ë°ì´í„° ì‚¬ìš©)")
        elif isinstance(loaded_data, dict):
            scan_data = loaded_data
            st.sidebar.success("âœ… íŒŒì¼ ë¡œë“œ ì™„ë£Œ!")
        else:
            st.sidebar.error("âŒ ì§€ì›ë˜ì§€ ì•ŠëŠ” JSON í˜•ì‹ì…ë‹ˆë‹¤.")
            scan_data = None

        if scan_data:
            st.session_state.scan_data = scan_data

    except json.JSONDecodeError as e:
        st.sidebar.error(f"âŒ JSON íŒŒì‹± ì˜¤ë¥˜: {str(e)}")
    except Exception as e:
        st.sidebar.error(f"âŒ íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {str(e)}")

# ì„¸ì…˜ ìƒíƒœì—ì„œ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
if 'scan_data' in st.session_state:
    scan_data = st.session_state.scan_data

# ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ì´ˆê¸° í™”ë©´ í‘œì‹œ
if scan_data is None:
    st.info("ğŸ‘† ì‚¬ì´ë“œë°”ì—ì„œ JSON íŒŒì¼ì„ ì—…ë¡œë“œí•˜ê±°ë‚˜ ìƒ˜í”Œ ë°ì´í„°ë¥¼ ì‚¬ìš©í•´ë³´ì„¸ìš”.")

    # ìƒ˜í”Œ ìŠ¤í¬ë¦°ìƒ·ì´ë‚˜ ì„¤ëª… ì¶”ê°€
    st.markdown("""
    ### ğŸ” ê°œì¸ì •ë³´ ìŠ¤ìº” ëŒ€ì‹œë³´ë“œ ì‚¬ìš©ë²•

    1. **ì‚¬ì´ë“œë°”**ì—ì„œ JSON íŒŒì¼ì„ ì—…ë¡œë“œí•˜ê±°ë‚˜
    2. **"ğŸ² ìƒ˜í”Œ ë°ì´í„° ì‚¬ìš©"** ë²„íŠ¼ì„ í´ë¦­í•˜ì„¸ìš”

    ### ğŸ“Š ëŒ€ì‹œë³´ë“œ ê¸°ëŠ¥
    - **ê°œìš”**: ì „ì²´ ìœ„í—˜ë„ ìš”ì•½ ë° í†µê³„
    - **í…Œì´ë¸” ë¶„ì„**: í…Œì´ë¸”ë³„ ìƒì„¸ ê°œì¸ì •ë³´ íƒì§€ ê²°ê³¼  
    - **íŒ¨í„´ ë¶„ì„**: ì´ë©”ì¼, ì „í™”ë²ˆí˜¸ ë“± íŒ¨í„´ë³„ ë¶„ì„
    - **ì„¤ì •**: ë°ì´í„° ë‚´ë³´ë‚´ê¸° ë° í‘œì‹œ ì˜µì…˜
    """)

    st.stop()

# ë©”ì¸ ëŒ€ì‹œë³´ë“œ - ë°ì´í„°ê°€ ìˆì„ ë•Œë§Œ ì‹¤í–‰
try:
    summary = scan_data.get('summary', {})
    tables_data = scan_data.get('tables', {})

    # ë°ì´í„° ìœ íš¨ì„± ê²€ì‚¬
    if not isinstance(scan_data, dict):
        st.error("âŒ ì˜ëª»ëœ ë°ì´í„° í˜•ì‹ì…ë‹ˆë‹¤. ì˜¬ë°”ë¥¸ JSON íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")
        st.stop()

    # í•„ìˆ˜ í‚¤ í™•ì¸ (summaryëŠ” ì„ íƒì‚¬í•­ìœ¼ë¡œ ë³€ê²½)
    if 'tables' not in scan_data:
        st.error("âŒ 'tables' ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. Polars ìŠ¤ìºë„ˆì—ì„œ ìƒì„±ëœ JSON íŒŒì¼ì„ ì‚¬ìš©í•´ì£¼ì„¸ìš”.")
        st.stop()

    # summaryê°€ ì—†ëŠ” ê²½ìš° ê¸°ë³¸ê°’ ìƒì„±
    if not summary:
        # tables ë°ì´í„°ì—ì„œ summary ê³„ì‚°
        high_risk = sum(1 for t in tables_data.values() if t.get('risk_level') == 'HIGH')
        medium_risk = sum(1 for t in tables_data.values() if t.get('risk_level') == 'MEDIUM')
        low_risk = sum(1 for t in tables_data.values() if t.get('risk_level') == 'LOW')
        total_score = sum(t.get('privacy_score', 0) for t in tables_data.values())
        total_data_rows = sum(t.get('sampling_info', {}).get('total_rows', 0) for t in tables_data.values())
        total_sampled_rows = sum(t.get('sampling_info', {}).get('sampled_rows', 0) for t in tables_data.values())

        summary = {
            'total_tables': len(tables_data),
            'scanned_tables': len(tables_data),
            'high_risk_tables': high_risk,
            'medium_risk_tables': medium_risk,
            'low_risk_tables': low_risk,
            'total_privacy_score': total_score,
            'total_data_rows': total_data_rows,
            'total_sampled_rows': total_sampled_rows
        }

        st.info("ğŸ“Š summary ë°ì´í„°ê°€ ì—†ì–´ì„œ ìë™ìœ¼ë¡œ ê³„ì‚°í–ˆìŠµë‹ˆë‹¤.")

except AttributeError:
    st.error("âŒ ì˜ëª»ëœ ë°ì´í„° í˜•ì‹ì…ë‹ˆë‹¤. ì˜¬ë°”ë¥¸ JSON íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")
    st.stop()
except Exception as e:
    st.error(f"âŒ ë°ì´í„° ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}")
    st.stop()

# íƒ­ ìƒì„±
tab1, tab2, tab3, tab4 = st.tabs(["ğŸ“Š ê°œìš”", "ğŸ“‹ í…Œì´ë¸” ë¶„ì„", "ğŸ” íŒ¨í„´ ë¶„ì„", "âš™ï¸ ì„¤ì •"])

with tab1:
    st.subheader("ìŠ¤ìº” ê°œìš”")

    # ê¸°ë³¸ ì •ë³´
    col1, col2 = st.columns([2, 1])

    with col1:
        st.info(f"""
        **ë°ì´í„°ë² ì´ìŠ¤**: {scan_data.get('database', 'Unknown')}  
        **ìŠ¤ìº” ì‹œê°„**: {scan_data.get('scan_time', 'Unknown')}  
        **ì²˜ë¦¬ ì—”ì§„**: {scan_data.get('engine', 'Unknown')}  
        **ìƒ˜í”Œ í¬ê¸°**: {scan_data.get('sample_size', 'Unknown')}ê±´
        """)

    with col2:
        total_score = summary.get('total_privacy_score', 0)
        if total_score >= 50:
            score_color = "ğŸ”´"
        elif total_score >= 20:
            score_color = "ğŸŸ¡"
        else:
            score_color = "ğŸŸ¢"

        st.metric("ì „ì²´ ìœ„í—˜ë„", f"{score_color} {total_score}ì ")

    # ë©”íŠ¸ë¦­ ì¹´ë“œë“¤
    col1, col2, col3, col4 = st.columns(4)

    with col1:
        st.metric(
            "ì´ í…Œì´ë¸”",
            f"{summary.get('total_tables', 0):,}ê°œ"
        )

    with col2:
        st.metric(
            "ê³ ìœ„í—˜ í…Œì´ë¸”",
            f"{summary.get('high_risk_tables', 0)}ê°œ",
            delta=f"ìœ„í—˜ë„ {total_score}ì "
        )

    with col3:
        st.metric(
            "ìŠ¤ìº”ëœ í–‰ ìˆ˜",
            f"{summary.get('total_sampled_rows', 0):,}í–‰",
            delta=f"ì „ì²´ {summary.get('total_data_rows', 0):,}í–‰"
        )

    with col4:
        sampling_ratio = 0
        if summary.get('total_data_rows', 0) > 0:
            sampling_ratio = summary.get('total_sampled_rows', 0) / summary.get('total_data_rows', 0) * 100

        st.metric(
            "ìƒ˜í”Œë§ ë¹„ìœ¨",
            f"{sampling_ratio:.2f}%"
        )

    # ìœ„í—˜ë„ ë¶„í¬ ì°¨íŠ¸
    st.subheader("í…Œì´ë¸” ìœ„í—˜ë„ ë¶„í¬")

    col1, col2 = st.columns([2, 1])

    with col1:
        # ë„ë„› ì°¨íŠ¸
        risk_counts = [
            summary.get('high_risk_tables', 0),
            summary.get('medium_risk_tables', 0),
            summary.get('low_risk_tables', 0)
        ]
        risk_labels = ['ê³ ìœ„í—˜', 'ì¤‘ê°„ìœ„í—˜', 'ì €ìœ„í—˜']
        risk_colors = ['#ff4444', '#ff8800', '#00cc44']

        fig_donut = go.Figure(data=[go.Pie(
            labels=risk_labels,
            values=risk_counts,
            hole=0.4,
            marker_colors=risk_colors
        )])

        fig_donut.update_layout(
            title="í…Œì´ë¸” ìœ„í—˜ë„ ë¶„í¬",
            height=400
        )

        st.plotly_chart(fig_donut, use_container_width=True)

    with col2:
        # ìœ„í—˜ë„ ë ˆë²¨ë³„ ì •ë³´
        st.markdown("### ìœ„í—˜ë„ ë ˆë²¨")

        for level, count, color in zip(risk_labels, risk_counts, risk_colors):
            if count > 0:
                st.markdown(f"""
                <div style="background-color: {color}22; padding: 0.5rem; border-radius: 0.25rem; margin-bottom: 0.5rem; border-left: 4px solid {color};">
                    <strong>{level}</strong>: {count}ê°œ
                </div>
                """, unsafe_allow_html=True)

with tab2:
    st.subheader("í…Œì´ë¸”ë³„ ìƒì„¸ ë¶„ì„")

    # í…Œì´ë¸” ë°ì´í„° ì¤€ë¹„
    table_list = []
    for table_name, table_info in tables_data.items():
        sampling_info = table_info.get('sampling_info', {})
        table_list.append({
            'Table': table_name,
            'Risk Level': table_info.get('risk_level', 'UNKNOWN'),
            'Privacy Score': table_info.get('privacy_score', 0),
            'Total Rows': f"{sampling_info.get('total_rows', 0):,}",
            'Sampled Rows': sampling_info.get('sampled_rows', 0),
            'Sampling Method': sampling_info.get('method', 'Unknown')
        })

    if table_list:
        # ì •ë ¬ ì˜µì…˜
        sort_by = st.selectbox("ì •ë ¬ ê¸°ì¤€", ["Privacy Score", "Risk Level", "Total Rows"])

        df_tables = pd.DataFrame(table_list)

        if sort_by == "Privacy Score":
            df_tables = df_tables.sort_values('Privacy Score', ascending=False)

        # í…Œì´ë¸” í‘œì‹œ (ìœ„í—˜ë„ë³„ ìƒ‰ìƒ)
        for idx, row in df_tables.iterrows():
            risk_level = row['Risk Level']
            color = get_risk_color(risk_level)

            with st.expander(f"ğŸ“‹ {row['Table']} (ìœ„í—˜ë„: {risk_level}, ì ìˆ˜: {row['Privacy Score']})"):
                col1, col2 = st.columns([1, 1])

                with col1:
                    st.write(f"**ì´ í–‰ ìˆ˜**: {row['Total Rows']}")
                    st.write(f"**ìƒ˜í”Œë§ëœ í–‰ ìˆ˜**: {row['Sampled Rows']}")
                    st.write(f"**ìƒ˜í”Œë§ ë°©ë²•**: {row['Sampling Method']}")

                with col2:
                    st.write(f"**ìœ„í—˜ë„ ë ˆë²¨**: {risk_level}")
                    st.write(f"**ê°œì¸ì •ë³´ ì ìˆ˜**: {row['Privacy Score']}")

                # ì»¬ëŸ¼ë³„ ìƒì„¸ ì •ë³´
                table_info = tables_data[row['Table']]
                columns_info = table_info.get('columns', {})

                if columns_info:
                    st.write("**ì»¬ëŸ¼ë³„ ê°œì¸ì •ë³´ íƒì§€ ê²°ê³¼**:")

                    col_data = []
                    for col_name, col_info in columns_info.items():
                        pattern_scan = col_info.get('pattern_scan', {})
                        privacy_matches = pattern_scan.get('privacy_matches', {}) if pattern_scan else {}
                        privacy_ratio = pattern_scan.get('privacy_ratio', 0) if pattern_scan else 0

                        col_data.append({
                            'Column': col_name,
                            'Type': col_info.get('type', 'Unknown'),
                            'Suspicious Name': 'âš ï¸' if col_info.get('suspicious_name') else 'âœ…',
                            'Privacy Patterns': ', '.join([f"{k}({v})" for k, v in privacy_matches.items()]) or 'None',
                            'Privacy Ratio': f"{privacy_ratio:.1%}" if privacy_ratio > 0 else '0%'
                        })

                    if col_data:
                        df_cols = pd.DataFrame(col_data)
                        st.dataframe(df_cols, use_container_width=True)

with tab3:
    st.subheader("ê°œì¸ì •ë³´ íŒ¨í„´ ë¶„ì„")

    # íŒ¨í„´ë³„ í†µê³„ ìˆ˜ì§‘
    pattern_stats = {}

    for table_name, table_info in tables_data.items():
        columns_info = table_info.get('columns', {})
        for col_name, col_info in columns_info.items():
            pattern_scan = col_info.get('pattern_scan', {})
            if pattern_scan and 'privacy_matches' in pattern_scan:
                privacy_matches = pattern_scan['privacy_matches']
                for pattern, count in privacy_matches.items():
                    if pattern not in pattern_stats:
                        pattern_stats[pattern] = []
                    pattern_stats[pattern].append({
                        'table': table_name,
                        'column': col_name,
                        'count': count,
                        'ratio': pattern_scan.get('privacy_ratio', 0)
                    })

    if pattern_stats:
        # íŒ¨í„´ë³„ ìš”ì•½
        pattern_summary = {}
        for pattern, occurrences in pattern_stats.items():
            total_count = sum(occ['count'] for occ in occurrences)
            avg_ratio = sum(occ['ratio'] for occ in occurrences) / len(occurrences)
            pattern_summary[pattern] = {
                'total_count': total_count,
                'avg_ratio': avg_ratio,
                'tables_affected': len(set(occ['table'] for occ in occurrences))
            }

        col1, col2 = st.columns(2)

        with col1:
            # íŒ¨í„´ë³„ ë°œê²¬ ê±´ìˆ˜
            patterns = list(pattern_summary.keys())
            counts = [pattern_summary[p]['total_count'] for p in patterns]

            fig_bar = px.bar(
                x=patterns,
                y=counts,
                title="íŒ¨í„´ë³„ ê°œì¸ì •ë³´ ë°œê²¬ ê±´ìˆ˜",
                labels={'x': 'íŒ¨í„´ íƒ€ì…', 'y': 'ë°œê²¬ ê±´ìˆ˜'}
            )
            fig_bar.update_traces(marker_color='#1f77b4')
            st.plotly_chart(fig_bar, use_container_width=True)

        with col2:
            # íŒ¨í„´ë³„ í‰ê·  ë¹„ìœ¨
            ratios = [pattern_summary[p]['avg_ratio'] * 100 for p in patterns]

            fig_ratio = px.bar(
                x=patterns,
                y=ratios,
                title="íŒ¨í„´ë³„ í‰ê·  í¬í•¨ ë¹„ìœ¨",
                labels={'x': 'íŒ¨í„´ íƒ€ì…', 'y': 'í‰ê·  ë¹„ìœ¨ (%)'}
            )
            fig_ratio.update_traces(marker_color='#ff7f0e')
            st.plotly_chart(fig_ratio, use_container_width=True)

        # ìƒì„¸ íŒ¨í„´ ì •ë³´
        st.subheader("íŒ¨í„´ë³„ ìƒì„¸ ì •ë³´")

        for pattern, info in pattern_summary.items():
            with st.expander(f"ğŸ” {pattern.upper()} íŒ¨í„´"):
                col1, col2, col3 = st.columns(3)

                with col1:
                    st.metric("ì´ ë°œê²¬ ê±´ìˆ˜", f"{info['total_count']:,}ê±´")

                with col2:
                    st.metric("í‰ê·  í¬í•¨ ë¹„ìœ¨", f"{info['avg_ratio']:.1%}")

                with col3:
                    st.metric("ì˜í–¥ë°›ì€ í…Œì´ë¸”", f"{info['tables_affected']}ê°œ")

                # í•´ë‹¹ íŒ¨í„´ì´ ë°œê²¬ëœ í…Œì´ë¸”/ì»¬ëŸ¼ ëª©ë¡
                pattern_details = pattern_stats[pattern]
                pattern_df = pd.DataFrame([
                    {
                        'Table': detail['table'],
                        'Column': detail['column'],
                        'Count': detail['count'],
                        'Ratio': f"{detail['ratio']:.1%}"
                    }
                    for detail in pattern_details
                ])

                st.dataframe(pattern_df, use_container_width=True)
    else:
        st.info("íŒ¨í„´ ë¶„ì„ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

with tab4:
    st.subheader("ì„¤ì • ë° ë„êµ¬")

    col1, col2 = st.columns(2)

    with col1:
        st.markdown("### ğŸ“Š ë°ì´í„° ë‚´ë³´ë‚´ê¸°")

        if st.button("ğŸ“¥ CSVë¡œ ë‚´ë³´ë‚´ê¸°"):
            # í…Œì´ë¸” ìš”ì•½ ë°ì´í„° CSV ìƒì„±
            if scan_data and tables_data:
                # í…Œì´ë¸” ë°ì´í„° ë‹¤ì‹œ ìƒì„± (ì•ˆì „í•˜ê²Œ)
                safe_table_list = []
                for table_name, table_info in tables_data.items():
                    try:
                        sampling_info = table_info.get('sampling_info', {})
                        safe_table_list.append({
                            'Table': table_name,
                            'Risk Level': table_info.get('risk_level', 'UNKNOWN'),
                            'Privacy Score': table_info.get('privacy_score', 0),
                            'Total Rows': f"{sampling_info.get('total_rows', 0):,}",
                            'Sampled Rows': sampling_info.get('sampled_rows', 0),
                            'Sampling Method': sampling_info.get('method', 'Unknown')
                        })
                    except Exception as e:
                        st.warning(f"í…Œì´ë¸” {table_name} ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}")
                        continue

                if safe_table_list:
                    df_export = pd.DataFrame(safe_table_list)
                    csv_data = df_export.to_csv(index=False)

                    st.download_button(
                        label="ë‹¤ìš´ë¡œë“œ CSV",
                        data=csv_data,
                        file_name=f"privacy_scan_summary_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                        mime="text/csv"
                    )
                else:
                    st.error("ë‚´ë³´ë‚¼ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            else:
                st.error("ìŠ¤ìº” ë°ì´í„°ë¥¼ ë¨¼ì € ë¡œë“œí•´ì£¼ì„¸ìš”.")

        if st.button("ğŸ“„ JSON ì›ë³¸ ë‹¤ìš´ë¡œë“œ"):
            if scan_data:
                try:
                    json_data = json.dumps(scan_data, ensure_ascii=False, indent=2)

                    st.download_button(
                        label="ë‹¤ìš´ë¡œë“œ JSON",
                        data=json_data,
                        file_name=f"privacy_scan_raw_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
                        mime="application/json"
                    )
                except Exception as e:
                    st.error(f"JSON ìƒì„± ì˜¤ë¥˜: {str(e)}")
            else:
                st.error("ìŠ¤ìº” ë°ì´í„°ë¥¼ ë¨¼ì € ë¡œë“œí•´ì£¼ì„¸ìš”.")

    with col2:
        st.markdown("### âš™ï¸ í‘œì‹œ ì„¤ì •")

        show_masked = st.checkbox("ë¯¼ê°ì •ë³´ ë§ˆìŠ¤í‚¹ í‘œì‹œ", value=True)
        show_empty_tables = st.checkbox("ë¹ˆ í…Œì´ë¸” í‘œì‹œ", value=False)

    # ì„¤ì • í˜ì´ì§€ì—ì„œë„ ë°ì´í„° í™•ì¸
    if scan_data and isinstance(scan_data, dict):
        st.markdown("### ğŸ“ˆ í†µê³„")
        st.write(f"**ìŠ¤ìº” ì™„ë£Œ ì‹œê°„**: {scan_data.get('scan_time', 'Unknown')}")
        st.write(f"**ì²˜ë¦¬ëœ ë°ì´í„°ë² ì´ìŠ¤**: 1ê°œ")
        st.write(f"**ì²˜ë¦¬ëœ í…Œì´ë¸”**: {summary.get('scanned_tables', 0)}ê°œ")
        processing_time = scan_data.get('processing_time', 'Unknown')
        st.write(f"**ì²˜ë¦¬ ì‹œê°„**: {processing_time}")
    else:
        st.info("ìŠ¤ìº” ë°ì´í„°ë¥¼ ë¨¼ì € ë¡œë“œí•´ì£¼ì„¸ìš”.")

# í‘¸í„°
st.markdown("---")
st.markdown(
    """
    <div style='text-align: center; color: #666; font-size: 0.8rem;'>
        ğŸ” Polars ê¸°ë°˜ ê°œì¸ì •ë³´ ìŠ¤ìº” ëŒ€ì‹œë³´ë“œ | 
        Made with â¤ï¸ using Streamlit & Plotly
    </div>
    """,
    unsafe_allow_html=True
)